大概目标：请求处理、消息生产、消息消费、事务协调器、组协调器、幂等、副本同步细节(ISR、LW、LEO)、日志处理细节、延迟消息
的时间轮应用



kafka broker代码里配置所在：KafkaConfig，配置默认值所在：Defaults

1、initZkClient()，初始化zookeeper客户端，并尝试创建kafka的基础信息节点：
    /consumers
    /brokers/ids
    /brokers/topics
    /config/changes
    /admin/delete_topics
    /brokers/seqid
    /isr_change_notification
    /latest_producer_id_block
    /log_dir_event_notification
    /config/topics
    /config/clients
    /config/users
    /config/brokers

    2、getOrGenerateClusterId()，获取或生成集群id，首先在zk的/cluster/id节点里找，如果找不到就生成一个uuid并放进去
然后返回

    3、getBrokerMetadataAndOfflineDirs()，从log.dirs目录中加载元数据，由于用户可以设置多个日志目录，还会校验这些
目录中meta.properties里的brokerId与clusterId是否全部一致，如果出现不一致则抛出InconsistentBrokerMetadataException

    4、校验meta.properties里的clusterId是否与zk里/cluster/id的一致，如果不一致抛出InconsistentClusterIdException

    5、getOrGenerateBrokerId()，会校验配置里的brokerId与meta.properties里的brokerId是否一致，不一致则抛出
InconsistentBrokerIdException，然后如果两个配置的brokerId都没配置(小于0)，则通过zk的/brokers/seqid节点生成一个
brokerId，brokerId = /brokers/sqeid的版本号 + reserved.broker.max.id

    6、从zk中更新配置，会读两个配置，分别是/config/broker/<default>与/config/broker/0，对应着默认配置与当前
brokerId的配置，zk中的配置会有更高的优先级，并且用户可以通过kafka-configs.sh脚本向zk的/config/changes节点中写入
数据，然后触发配置变更，以此实现动态配置

    7、创建KafkaScheduler，内部就是一个java的任务调度器，线程数是background.threads，默认为10

    8、创建quotaManagers，配额管理器

    9、创建logManager，日志管理器，这个日志是kafka存消息的日志

    10、创建metadataCache，它有着每个分区的元数据缓存，例如它的leader信息

    11、创建tokenCache与credentialProvider，它们提供鉴权相关的功能

    12、创建socketServer，这个组件是kafka用来创建服务器与处理请求的。其内部包含了Acceptor与processor，其中
Acceptor只有一个，而processor取决于num.network.threads。主线程会等待Acceptor启动完成后才会继续，这个行为通过
一个在Acceptor内部的CountDownLatch对象来进行：主线程拿锁等待，Acceptor线程释放锁。这一步暂时还不会启动
Processor，因为要等服务器完全初始化后才能启动处理器
    kafka的请求处理器分为两种：controlPlane和dataPlane，分别是控制面板与数据面板，其中控制面板controlPlane是管理
集群请求的，需要配置control.plane.listener.name属性才会初始化；数据面板dataPlane是管理生产与消费者请求的，这个一
定会启用
    控制面板的服务器配置放在listeners配置中，多个配置多逗号隔开，例如端口，好像也可以写一个url
        
    13、创建replicaManager，副本管理器，然后调用它的startup方法，里面会启动几个调度任务：isr-expiration、
isr-change-propagationshutdown-idle-replica-alter-log-dirs-thread。还会启动一个LogDirFailureHandler线程，这个是
处理失败副本的处理器

    14、创建/brokers/ids/{brokerId}的zk临时节点，并设置节点的data，data里包含当前broker的一些信息，例如端口、
主机名、当前broker的节点路径、jmxPort等

    15、将brokerId、clusterId、version等信息写入meta.properties文件

    16、启动tokenManage，token管理器，token管理器是否会真正干活取决于delegation.token.master.key是否有配置，
它对应着zk里的/delegation_token节点

    17、启动kafkaController集群控制器，然后调用它的startup方法，这个方法会在zk客户端里注册一个状态变更处理器，
用于监听broker与zk之间的会话是否过期，然后往eventManager事件管理器里添加一个StartUp启动事件，然后启动事件
管理器，事件管理器里对StartUp事件的处理是，往zk注册一个节点变更监听器，监听节点为：/controller，当监听到该节点
发生不同的变更时，就往事件管理器里添加不同的事件，例如：Reelect(重选事件)、ControllerChange(控制器变更事件)
    然后就会尝试去获取/controller节点的数据，加入发现/controller节点的数据是空的，就会尝试自己去注册，也就是尝试创
建/controller临时节点，节点数据里brokerId是当前节点的brokerId，然后设置/controller_epoch的数据，epoch的设置会
附带版本号，相当于有个乐观锁的操作，当临时节点与epoch都设置成功，则返回当前设置成功的epoch与节点version
    如果/controller节点创建失败或者/controller_epoch数据设置失败，则抛出ControllerMovedException异常，代表其它
broker成为了控制器，然后捕获ControllerMovedException异常后就会为/controller注册监听器，并从zk拿到controllerId
放到kafkaController.activeControllerId中。选举成功则直接拿当前的brokerId放到kafkaController.activeControllerId，此
外还会设置controllerContext.epoch、controllerContext.epochZkVersion

    18、创建adminManager，看起来像是一个内部使用的对一些操作的封装，例如创建主题、创建分区

    19、创建groupCoordinator，组协调器，并调用它的startup方法，这个startup方法会启动一个调度任务：
delete-expired-group-metadata，用来清除过期的消费组

    20、创建transactionCoordinator，事务协调器，并调用它的startup方法，这个startup方法会启动一个调度任务：
transaction-abort，用来中断超时的事务

    21、如果配置指定了授权信息，则对授权进行初始化

    22、创建fetchManager，拉取管理器

    23、创建KafkaApis放在dataPlaneRequestProcessor变量里，这个类用来处理不同的api，里面有个handle方法，用了
switch跳到不同的方法处理不同的API请求

    24、创建KafkaRequestHandlerPool放在dataPlaneRequestHandlerPool变量里，这个对象在内部会启用多个线程，这些
线程会从RequestChannel里的请求队列中拿出请求，然后用KafkaApis处理请求，线程数量取决于num.io.threads参数，默认
为8。这个线程池是processor线程将连接处理成Request对象后，放进一个requestQueue队列中，由这个线程将Request拿出来
进行后续处理

    25、增加一系列的动态配置监听器与动态配置处理器，然后启动一个dynamicConfigManager动态配置管理器，并调用它
的startup方法，这个方法就是在zk的/config/changes节点注册一个监听器，然后启用一个线程，一直从配置变更队列里获取
事件并触发各种监听器

    26、启动控制面与数据面的processor线程，到了这里已经开始正式处理请求了

    27、然后设置kafka的各种状态，到这里基本已经启动完成了，最后注册mbean，输出个started日志，至此启动完毕



请求基础流程：
    1、先是Acceptor线程，先进行select，最多等待500ms，然后遍历select到的key，确认key可握手后，先进行握手
    2、有个connectionQuotas连接配额用来进行连接数限制，还可以配置每个监听器的最大连接数，不过默认是int.max，还
能通过max.connections参数来限制整个broker的总连接数，默认也是int.max，假设这两个连接数超过了就会一直阻塞，直到
有旧的请求结束对其进行唤醒。
    还有地址级别的请求限制，如果有通过max.connections.per.ip.overrides配置每个地址的最大连接数，则取地址配置的连接
数进行限制，如果该地址没有特意去配置，最大连接数就取max.connections.per.ip，当这个地址的连接数超过最大连接数时
，就会抛出TooManyConnectionsException异常，上层捕获到这个异常后会关闭scoket
    3、connectionQuotas的连接数限制通过后，就会返回selectionKey里的socketChannel，并设置它的一些属性
    4、将processor的数量放入retriesLeft变量，用来当做重试次数；然后用currentProcessorIndex对processor的数量进行
取模，这个变量每次都会+1，用来轮询所有的processor，然后就在超过重试次数之前一直轮processor，去调assignNewConnection
方法，如果返回false就代表请求处理完成，如果返回true就换下一个processor
    5、拿processor去执行assignNewConnection方法，这个方法里面就是将socketChannel放入processor的newConnections
，如果放成功就返回true，否则就看是不是轮询到最后一个processor了，如果不是最后一个直接返回false，如果是最后一个
则改用put方法，一直等到newConnections有空位。其实总的来说就是尽量放进一个有空间的processor，如果实在没有就在
最后一个processor硬等

    6、然后到Processor线程，首先执行selector.register，这个selector并不是nio的，而是kafka的。它的注册先校验这个连接
id是否已经存在它的连接池中了，如果是则抛出异常，id一般是不会重复的，因为每个processor都有一个index，每次新连接
都会+1，并且最大值是int.max，达到最大值会重置到0。第二部是将socketChannel注册到nioSelector中，并监听READ事件
，然后将连接id绑定到selectionKey中的attach，在将该连接放入连接池与空闲连接管理器中

    7.0、这里漏了个processNewResponses()方法，它会从responseQueue队列里拿响应出来发送响应数据，懒得改数字了，干脆
写个7.0

    7、开始poll方法，这个poll也是进行selectedKey，不同的是这里的Selector里面只注册了读事件，前面那个Selector里只
注册了握手事件
    8、poll方法里，如果连接已经可读，就会用nioSelector.selectdKeys方法select到一批可读的key放到readyKeys变量中，然后
用pollSelectionKeys()方法处理这批readyKeys可读key
    9、pollSelectionKeys()方法会遍历所有的key，首先在空闲管理器里更新这个连接id的活跃时间，然后期间一堆额外工作，正常
来讲会进入attemptRead方法中，就是处理可读的连接，这里面会执行一个channel.read()方法，就是将数据从流里读出来，然后一直
往里执行会走到一个receive.readFrom()方法，这个方法里会先读4b的数据，然后将这4b当做请求内容的大小去重新分配缓冲区，如果
分配成功就全读出来，如果分配失败就会将缓冲区置为Null，并且记录需要分配的内存，然后在上层的kafkaChannel.read中就会执行
mute()方法，这个方法会将kafkaChannel的状态改为MUTED，这意味着内存池没有足够的内存用来处理该请求，也就是将请求静默，然后
删除它的READ事件，然后将processor里的selector.outOfMemory设置为true。如果内存足够，则将kafkaChannel放入完成接收集合：completedReceives。这里的疑惑是kafka前面4b究竟是不是整个请求的长度？书上不是这么讲的

    10、然后是processCompletedReceives()方法，处理已经完全读完流的连接，这里只说正常情况下的流程，非正常的流程很简单，
就是抛异常，这里直接略过。
    10.1、执行RequestHeader.parse解析请求头，这里的解析过程与书上讲的协议格式一样，16位的apiKey、16为的apiVersion、然后
32位请求id，再读16位的cliendId长度，根据长度读数据。然后读取一个变长int的字段数量，再根据字段数量读取每个字段，放到集合
里，起名叫未知标记字段_unknownTaggedFields，不知道这是什么东西，这个有什么用？找不到注释网上也查不到作用
    10.2、然后用header与连接的信息创建一个RequestContext对象，再用RequestContext对象创建一个RequestChannel.Request对象
。再调用requestChannel.sendRequest()方法将req对象放入requestQueue队列中；再将这个连接静默，且将其加入
explicitlyMutedChannels集合中；最后执行一个handleChannelMuteEvent()方法将这个kafkaChannel的muteState静默状态改为
ChannelMuteState.MUTED_AND_RESPONSE_PENDING既静默且等待响应
    10.3、上面的requestQueue会被KafkaRequestHandler线程，这个线程就是每次拿一个req出来处理
    10.4、req分两种：ShutdownRequest与Request，一般而言都是Request，Request会直接跳转到KafkaApis.handle()方法

    11、再然后是processCompletedSends()方法，处理响应发送完成的一些操作，例如从正在响应列表中删除该链接、调用请求完成
回调、将连接改为非静默

    12、再然后调用processDisconnected()方法，将已关闭的连接的连接配额进行回收、

    13、最后是调用closeExcessConnections()方法，关闭多余的连接，这里的多余连接是因为最大连接数是支持动态配置的，因此
如果有大量请求的情况下突然改了配置，就会导致连接过多。当出现这种情况则会挑选一个连接，挑选逻辑是：先看正在关闭连接里
有没有连接，如果有就拿第一个；如果没有就看过期管理器里有没有连接，如果有就拿最快过期的；如果还没有就从连接集合里拿第
一个，这往往是最早的请求。拿到的连接如果不为空就对这个连接进行close
    为什么过期管理器IdleExpiryManager里第一个总是最快过期的，因为它里面是个LinkedHashMap，而后面put的数据每次都是刷新
过期时间的，因所以前面的就是最久没刷新过的，因此前面的总是最旧的



消息生产请求(ProduceRequest)：

    1、从上面的请求基础流程的10.4开始，进入KafkaApis.handle()方法，里面会匹配到ApiKeys.PRODUCE，随后进入
handleProduceRequest()方法
    2、handleProduceRequest()方法会有一个让人难以理解的操作：request.body[ProduceRequest]，这个body点进去，其实返回的
是bodyAndSize对象的request属性，bodyAndSize对象其实早在Request对象构建时就解析好了，在构造器里干的活，往里面跟会发现
有一句AbstractRequest.parseRequest(apiKey, apiVersion, struct)，这里其实就是根据apiKey将初始的请求转成各种详细的类型，
然后到了request.body[ProduceRequest]只是做了个类型转换而已
    3、然后看这批消息里是否存在事务，如果存在则将事务id取出，并进行校验，如果校验不通过则抛出异常，异常已经在Errors类
定义好了，直接拿就好；否则就看是否幂等消息，如果是也进行校验，校验不通过也抛出一个Errors类的异常
    4、然后构建几个集合：unauthorizedTopicResponses(未授权的topic)、nonExistingTopicResponses(不存在的topic)、
invalidRequestResponses(消息无效，例如版本不匹配)、authorizedRequestInfo(授权通过)，这些集合都是map，用TopicPartition
当key
    5、然后就是构建响应回调方法sendResponseCallback()与统计回调方法processingStatsCallback()，这是两个闭包方法，后面
才会调，因此这里暂且略过
    6、如果授权通过集合authorizedRequestInfo是空的，则调用sendResponseCallback响应一个空Map，否则就调用副本管理器
replicaManager.appendRecords()方法添加消息
    7、最后将请求里的消息清空，以便让GC回收，因为执行完replicaManager.appendRecords()方法后，要么消息已经加入了日志文
件，要么消息已经放入了炼狱缓冲区，因此继续持有这个消息引用反而可能导致消息处理完后不能被GC回收
    8、消息响应流程，待看

副本管理器的消息追加：
    1、执行replicaManager.appendRecords()方法将进行消息追加，接消息生产请求的第6点，因为副本管理器算是一个较为独立的
模块，因此分开记录
    2、先看acks是否有效，既等于-1、1、0中任意一个值，如果有效就继续，否则响应InvalidRequiredAcksException异常
    3、执行appendToLocalLog()方法，这个方有4个参数：
        internalTopicsAllowed：代表是否允许操作内部主题，例如偏移量与事务状态，这个参数只有AdminClient才会为true
        origin：操作来源，类型为AppendOrigin，有三个子类，分别代表副本、协调器、客户端，生产者请求的话就是Client客户端
        entriesPerPartition：此次生产的消息
        requireAcks：acks，0、1、-1
    4、如果acks有效就调用appendToLocalLog()方法，然后遍历每个分区的消息，首先判断是否内部主题，如果是内部主题且
internalTopicsAllowed为false，则抛出InvalidTopicException异常，如果不是则继续执行日志追加
    5、通过getPartitionOrException()方法拿到当前分区的leader的分区对象，类型为Partition，副本管理器里的allPartitions
属性持有这个对象，如果allPartitions中没有这个分区，但是metadataCache又有，且要求返回leader的partition时既
expectLeader为true，就会返回NOT_LEADER_FOR_PARTITION分区没有leader错误
    6、调用partition.appendRecordsToLeader将消息追加到leader，这里面会根据Partition.eaderReplicaIdOpt是否等于当
前brokerId来判断当前broker是否该分区的leader，如果不是则抛出NotLeaderForPartitionException异常，表示当前broker
不是该分区的leader，如果当前broker是leader，则继续执行，这块逻辑调用之前会获取leaderIsrUpdateLock读写锁的读锁
    7、先获取配置的最小同步副本数量min.insync.replicas，默认为1，然后获取当前的同步副本数量，在
partition.inSyncReplicaIds属性里，这里保存了同步副本的brokerId集合，如果同步副本的数量少于配置要求的最小同步副本
，则抛出NotEnoughReplicasException异常，提示当前的同步副本无法满足最少同步副本的要求
    8、到了这一步就已经确定当前broker就是这个分区的leader了，然后调用partition.log对象的appendAsLeader方法，
这个方法里包了一层maybeHandleIOException()方法，当出现IO异常的时候就会将日志目录加入离线日志目录offlineLogDirs
与offlineLogDirQueue中













