

kafka broker代码里配置所在：KafkaConfig，配置默认值所在：Defaults

1、initZkClient()，初始化zookeeper客户端，并尝试创建kafka的基础信息节点：
    /consumers
    /brokers/ids
    /brokers/topics
    /config/changes
    /admin/delete_topics
    /brokers/seqid
    /isr_change_notification
    /latest_producer_id_block
    /log_dir_event_notification
    /config/topics
    /config/clients
    /config/users
    /config/brokers

    2、getOrGenerateClusterId()，获取或生成集群id，首先在zk的/cluster/id节点里找，如果找不到就生成一个uuid并放进去
然后返回

    3、getBrokerMetadataAndOfflineDirs()，从log.dirs目录中加载元数据，由于用户可以设置多个日志目录，还会校验这些
目录中meta.properties里的brokerId与clusterId是否全部一致，如果出现不一致则抛出InconsistentBrokerMetadataException

    4、校验meta.properties里的clusterId是否与zk里/cluster/id的一致，如果不一致抛出InconsistentClusterIdException

    5、getOrGenerateBrokerId()，会校验配置里的brokerId与meta.properties里的brokerId是否一致，不一致则抛出
InconsistentBrokerIdException，然后如果两个配置的brokerId都没配置(小于0)，则通过zk的/brokers/seqid节点生成一个
brokerId，brokerId = /brokers/sqeid的版本号 + reserved.broker.max.id

    6、从zk中更新配置，会读两个配置，分别是/config/broker/<default>与/config/broker/0，对应着默认配置与当前
brokerId的配置，zk中的配置会有更高的优先级，并且用户可以通过kafka-configs.sh脚本向zk的/config/changes节点中写入
数据，然后触发配置变更，以此实现动态配置

    7、创建KafkaScheduler，内部就是一个java的任务调度器，线程数是background.threads，默认为10

    8、创建quotaManagers，配额管理器

    9、创建logManager，日志管理器，这个日志是kafka存消息的日志

    10、创建metadataCache，它有着每个分区的元数据缓存，例如它的leader信息

    11、创建tokenCache与credentialProvider，它们提供鉴权相关的功能

    12、创建socketServer，这个组件是kafka用来创建服务器与处理请求的。其内部包含了Acceptor与processor，其中
Acceptor只有一个，而processor取决于num.network.threads。主线程会等待Acceptor启动完成后才会继续，这个行为通过
一个在Acceptor内部的CountDownLatch对象来进行：主线程拿锁等待，Acceptor线程释放锁。这一步暂时还不会启动
Processor，因为要等服务器完全初始化后才能启动处理器
    kafka的请求处理器分为两种：controlPlane和dataPlane，分别是控制面板与数据面板，其中控制面板controlPlane是管理
集群请求的，需要配置control.plane.listener.name属性才会初始化；数据面板dataPlane是管理生产与消费者请求的，这个一
定会启用
    控制面板的服务器配置放在listeners配置中，多个配置多逗号隔开，例如端口，好像也可以写一个url
        
    13、创建replicaManager，副本管理器，然后调用它的startup方法，里面会启动几个调度任务：isr-expiration、
isr-change-propagationshutdown-idle-replica-alter-log-dirs-thread。还会启动一个LogDirFailureHandler线程，这个是
处理失败副本的处理器

    14、创建/brokers/ids/{brokerId}的zk临时节点，并设置节点的data，data里包含当前broker的一些信息，例如端口、
主机名、当前broker的节点路径、jmxPort等

    15、将brokerId、clusterId、version等信息写入meta.properties文件

    16、启动tokenManage，token管理器，token管理器是否会真正干活取决于delegation.token.master.key是否有配置，
它对应着zk里的/delegation_token节点

    17、启动kafkaController集群控制器，然后调用它的startup方法，这个方法会在zk客户端里注册一个状态变更处理器，
用于监听broker与zk之间的会话是否过期，然后往eventManager事件管理器里添加一个StartUp启动事件，然后启动事件
管理器，事件管理器里对StartUp事件的处理是，往zk注册一个节点变更监听器，监听节点为：/controller，当监听到该节点
发生不同的变更时，就往事件管理器里添加不同的事件，例如：Reelect(重选事件)、ControllerChange(控制器变更事件)
    然后就会尝试去获取/controller节点的数据，加入发现/controller节点的数据是空的，就会尝试自己去注册，也就是尝试创
建/controller临时节点，节点数据里brokerId是当前节点的brokerId，然后设置/controller_epoch的数据，epoch的设置会
附带版本号，相当于有个乐观锁的操作，当临时节点与epoch都设置成功，则返回当前设置成功的epoch与节点version
    如果/controller节点创建失败或者/controller_epoch数据设置失败，则抛出ControllerMovedException异常，代表其它
broker成为了控制器，然后捕获ControllerMovedException异常后就会为/controller注册监听器，并从zk拿到controllerId
放到kafkaController.activeControllerId中。选举成功则直接拿当前的brokerId放到kafkaController.activeControllerId，此
外还会设置controllerContext.epoch、controllerContext.epochZkVersion

    18、创建adminManager，看起来像是一个内部使用的对一些操作的封装，例如创建主题、创建分区

    19、创建groupCoordinator，组协调器，并调用它的startup方法，这个startup方法会启动一个调度任务：
delete-expired-group-metadata，用来清除过期的消费组

    20、创建transactionCoordinator，事务协调器，并调用它的startup方法，这个startup方法会启动一个调度任务：
transaction-abort，用来中断超时的事务

    21、如果配置指定了授权信息，则对授权进行初始化

    22、创建fetchManager，拉取管理器

    23、创建KafkaApis放在dataPlaneRequestProcessor变量里，这个类用来处理不同的api，里面有个handle方法，用了
switch跳到不同的方法处理不同的API请求

    24、创建KafkaRequestHandlerPool放在dataPlaneRequestHandlerPool变量里，这个对象在内部会启用多个线程，这些
线程会从RequestChannel里的请求队列中拿出请求，然后用KafkaApis处理请求，线程数量取决于num.io.threads参数，默认
为8

    25、增加一系列的动态配置监听器与动态配置处理器，然后启动一个dynamicConfigManager动态配置管理器，并调用它
的startup方法，这个方法就是在zk的/config/changes节点注册一个监听器，然后启用一个线程，一直从配置变更队列里获取
事件并触发各种监听器

    26、启动控制面与数据面的processor线程，到了这里已经开始正式处理请求了

    27、然后设置kafka的各种状态，到这里基本已经启动完成了，最后注册mbean，输出个started日志，至此启动完毕



请求：
    1、先是Acceptor线程，先进行select，最多等待500ms，然后遍历select到的key，确认key可握手后，先进行握手
    2、有个connectionQuotas连接配额用来进行连接数限制，还可以配置每个监听器的最大连接数，不过默认是int.max，还
能通过max.connections参数来限制整个broker的总连接数，默认也是int.max，假设这两个连接数超过了就会一直阻塞，直到
有旧的请求结束对其进行唤醒。
    还有地址级别的请求限制，如果有通过max.connections.per.ip.overrides配置每个地址的最大连接数，则取地址配置的连接
数进行限制，如果该地址没有特意去配置，最大连接数就取max.connections.per.ip，当这个地址的连接数超过最大连接数时
，就会抛出TooManyConnectionsException异常，上层捕获到这个异常后会关闭scoket
    3、connectionQuotas的连接数限制通过后，就会返回selectionKey里的socketChannel，并设置它的一些属性
    4、将processor的数量放入retriesLeft变量，用来当做重试次数；然后用currentProcessorIndex对processor的数量进行
取模，这个变量每次都会+1，用来轮询所有的processor，然后就在超过重试次数之前一直轮processor，去调assignNewConnection
方法，如果返回false就代表请求处理完成，如果返回true就换下一个processor
    5、拿processor去执行assignNewConnection方法，这个方法里面就是将socketChannel放入processor的newConnections
，如果放成功就返回true，否则就看是不是轮询到最后一个processor了，如果不是最后一个直接返回false，如果是最后一个
则改用put方法，一直等到newConnections有空位。其实总的来说就是尽量放进一个有空间的processor，如果实在没有就在
最后一个processor硬等
    6、然后到Processor线程，首先执行selector.register，这个selector并不是nio的，而是kafka的。它的注册先校验这个连接
id是否已经存在它的连接池中了，如果是则抛出异常，id一般是不会重复的，因为每个processor都有一个index，每次新连接
都会+1，并且最大值是int.max，达到最大值会重置到0。第二部是将socketChannel注册到nioSelector中，并监听READ事件
，然后将连接id绑定到selectionKey中的attach，在将该连接放入连接池与空闲连接管理器中
    7、开始poll方法，这个poll也是进行selectedKey，不同的是这里的Selector里面只注册了读事件，前面那个Selector里只
注册了握手事件





























