
客户端：


生产者：

    生产流程：
        1、生产者调send方法进行消息发送：KafkaProducer.send
        2、一进来直接走生产者拦截器的onSend方法
        3、拉取集群的信息，也就是构建一个Cluster对象，这个对象包含了生产者感兴趣的topic对应的分区与节点信息，包括集
    群控制器是哪个节点、当前集群里有哪些节点、每个节点里有哪些分区、每个topic有哪些分区、每个分区的leader是哪个节
    点等等，都保存在一大堆Map里面，主要有两种对象：Node：节点信息，PartitionInfo：分区信息，每个对象代表一个分
    区，包含了leader节点是哪个、副本在哪些节点、同步节点是哪些、非同步节点是哪些等信息
        4、通过key与value序列化器对key与value进行序列化，将它们转成byte数组
        5、如果消息未指定分区，则用分区器进行分区，默认是DefaultPartitioner分区器。它通过key进行分区。如果key为null
    ，则通过一个topic独有的计数器进行自增与可用分区进行取模来分区。如果key不为null，则将key计算哈希，并与总分区数
    进行取模来分区
        6、将record.headers()设置为只读，这意味着消息头的内容后续无法被修改
        7、估算出这条消息的大小，然后判断是否超出单条消息的最大限制或者生产者缓冲区大小
        8、将消息加入RecordAccumulator累加器
            8.1：为指定topic分区获取一个ProducerBatch泛型的队列，如果已有则拿旧的，否则创建新的
            8.2：尝试将消息加入队列的最后一个批次里面，如果它还有空间，也就是原大小(可能是压缩过的)+当前消息的大小小
        于batch.size。或者批次里连一个消息都没有，那么就不管大小，至少让批次放一个消息
            8.3：如果该队列里没有批次，则从BufferPool类型的free里分配一段ByteBuffer缓存出来，分配的内存在batch.size与
        当前消息大小之间取大的值。缓存池里的缓存是可以被复用的，它将在批次发送之后回收(待确定)
            8.4：创建一个新的ProducerBatch批次，并未它分配缓存内存，然后加入分区队列里，并尝试将消息加入这个批次，
        由于这是一个全新批次，因此这次总会成功。
            8.5：加入成功后会将future与用户的callback绑定在Thunk对象并保存在batch的thunks里，这个似乎是为了触发
        callback时保证消息回调的顺序与生产的顺序相同
            8.6：所有ProducerBatch的append都是同步代码块下进行，因此不会因为并发导致批次大小溢出
        9、sender线程，sender线程是在KafkaProducer的构造器里启动的
        10、sender线程的内容大概为：
            1、如果处于running状态下，则一直尝试消费RecordAccumulator累加器并发送消息
            2、如果不处于running状态，且不是强制关闭，且累加器里还有消息，则将累加器里剩余的消息发送完成
            3、如果是强制关闭，则中断累加器里所有的消息，就是批次不允许再追加、删除队列里所有批次、完成批次的future
        、回收分配的内存
            4、关闭客户端
        11、sendProducerData方法从累加器里获取批次并发送
            11.1：拿到累加器里所有分区的leader节点，如果没有leader且批次队列里有数据，则将topic加入
        unknownLeaderTopics，也就是无leader的topic集合
            11.2：判断队列里的第一个分区是否就绪，例如是否达到批次等待最大时间、批次是否已满、缓存池是否有线程在等待
        分配、累加器是否已被关闭等待，如果满足这些条件任意一个，且不是重试批次且小于重试间隔，就会将leader加入就绪
        节点中返回去，此外还有一个下次重试时间，它会取所有批次重试间隔里最短的返回去，用来跟单次请求间隔取最小值来
        进行nio的select(timeout)操作，而它默认是Integer.max，因此可发送的情况下用的是请求超时的参数
            11.3：因此上面两步操作返回的值包括：无leader的topic列表、批次可以发送的leader列表、下次select时间
            11.4：如果未知leader的topic列表不为空，则将对应的topic加入metadata中，并尝试去更新集群的元数据
            11.5：如果ready的leader节点列表不为空，则判断每个节点是否就绪，例如客户端中节点同时发送的最大请求是否达
        到上限、客户端的各种组件状态是否正常，例如selector与channel等等，如果客户端判断该节点未就绪则将该节点从就
        绪集合中移除，并根据节点的重连接时间配置来决定下次select的时间，依然是跟上面的下次select时间取最小值
            11.6：调用accumulator.drain方法，去拿到可用leader里所有可发送的批次
            11.7：isMuted方法是用来判断该分区是否有正在发送的消息，如果有说明配置要求保证消息顺序，因此只能等上次消
        息发送完成后才能发送，而这次跳过这个分区
            11.8：如果不是重试且未满足重试间隔、且未到达最大请求字节数，就从队列里poll出第一个批次，将这个批次关闭，
        然后加入批次就绪集合中返回。每次sender线程轮询都只会拿每个批次队列里的第一个批次，哪怕后面也有就绪的也要等
        下次
            11.9：如果要保证消息的顺序性，也就是guaranteeMessageOrder为true，也就是
        max.in.flight.requests.per.connection等于1，就会将分区加入累加器的muted集合中，在muted集合中已有的分区就不
        会发送消息，只能等上次发送完后从muted中清除对应的分区才能发下次
            11.10：查找累加器中的过期批次，比如批次创建时间大于请求最大等待时间，就会将批次删除，传入超时异常回调批
        次里的future、回收缓存、记录指标等等，通过这种方式进行的超时是不会重试的，因为它直接进行回调了
            11.11：更新生产者请求的各项指标
            11.12：如果有就绪的leader节点，就将下次select的时间设置为0
            11.13：调用sendProduceRequests正式发送批次消息
            11.14：遍历batches发送消息，这是个map，key为nodeId，value为批次队列，因此每次只给一个发送节点
            11.15：包装成一个RequestCompletionHandler callback对象，这个对象里有一个外部构建的map，key是TopicPartition
        ，value是此次该分区发送的批次，每次每个分区只会发送一个批次，回调里也包含了TopicPartition，因此可以根据响应
        从map里拿到批次，然后进行回调
            11.16：创建一个clientRequest对象，这个client是跟节点绑定的业务request，然后KafkaClient.send，这个client是
        共用的client
            11.17：将请求构建成一个InFlightRequest inFlightRequest对象，然后保存到inFlightRequests中，这里记录的是当
        前所有正在发送的请求
            11.18：以上只是将request注册到selectKey里，它们通过一个KafkaChannel对象来关联
            11.19：client.poll，进行select
            11.20：client.poll后，里面有个metadataUpdater.mybeUpdate，这是发送更新元数据请求的，还有个selector.poll
        ，这是处理就绪的SelectionKey
            11.20：select到key之后，就会调用pollSelectionKeys方法处理key，这个方法里面有个attemptRead(key)操作，这是
        用来将读到的数据转成NetworkReceive的，NetworkReceive就是响应数据的包装，然后保存到stagedReceives里
            11.21：selector.poll的最下一行会调用addToCompletedReceives，将所有receive都加入completedReceives里
            11.22：然后再client.poll里，调用handleCompletedReceives方法，将receive用AbstractResponse.parseResponse
        转成AbstractResponse对象，这个对象会根据api的key转成不同的响应类型，如果这些响应是元数据或者api版本响应，
        则去更新元数据与api版本的信息，否则就都转成ClientResponse类型加入List<ClientResponse> responses对象中
            11.23：在client.poll里，调用completeResponses方法去处理所有的responses，也就是调用它们的callback
            11.24：在handleCompletedReceives中，response和callback的关联保存在inFlightRequests集合里，这个集合保存
        了所有正在请求的对象，每个响应 都从对应的节点请求集合里拿一个最早发起的请求对象，那么怎么保证最早发起的请求
        一定是最早响应的。因为对于相同的node，每个KafkaProducer只会创建一个连接，因此响应都是顺序返回的。
            

    kafka缓存池的消息存储：
        每个批次都会分配一段内存，批次的发送结束后回收内存，内存指的是一个ByteByffer对象，消息写入批次时，会按照
    key、value、headers的顺序写入，先写入key的长度，再写key的内容，value也一样，headers则先写入header的数量，
    然后再写每个header的长度与内容

    metadata的更新：
        在client.poll里，有个metadataUpdater.maybeUpdate(now)方法，里面会调用maybeUpdate，里面会构建一个
    metadataRequest请求，然后注册到select上，这里会选择一个调用最少的节点进行元数据拉取

    ApiVersions：
        这里的Api指的是操作的类型，比如生产消息、心跳、元数据拉取等待，都在ApiKeys里，由于Kafka有多个不同的版本，
    因此通过从节点拉取api版本列表的确定broker支持哪些api的哪个版本

    错误重试：
        重试是在处理响应的callback时处理的，会将批次进行重新发送，直接加入累加器的队列中，且会加在头部。可以在
    sender的sendProduceRequest方法中看到，里面会创建一个RequestCompletionHandler callback用来构建客户端，这里
    面就包含了重试逻辑，比如重试次数判断，是否是重试异常等等

    好像过期的批次，进行回调后依然会进行发送？

        kafka发送消息时，NetworkClient的InFlightRequests正在发送队列满了咋办，此时会判断是否内部消息，比如元数据或API版
    本请求，如果是的话就硬发，如果不是，比如消息生产请求，就会抛出IllegalStateException异常
        由于sender线程在从RecordAccumulator里拿批次前就会判断该节点请求是否可用，如果可用才会拿，而sender是单线程的，能
    保证不会超，所以正常情况下是不会出现poll出了批次，请求又满了的情况，如果真的出现了，这次发送的所有批次应该都会因为
    报错导致丢失


消费者：

        假设消费者消费到的偏移量是7，那么此时提交的偏移量就是8，也就是提交的偏移量总是会比消费到的+1，在日志里的
    偏移量也一样

        由于消费者是线程不安全的，因此大部分操作内部都会先调用acquire()，结束时调用release()，这是一个加锁操作，通过
    CAS获取当前线程id进行加锁，如果CAS失败，就代表多个线程在同时操作consumer，就会抛出异常，提示节点未准备好发送请求






ISR(In-Sync Replicas)：
    同步副本

优先副本：
    指进行leader选举时，该副本会优先被选举为leader

分区重分配：
    如果某个broker挂了，它的分区又有多个副本，此时最多就会将leader转移到其他副本上。但是这个分区的副本已经处于不
可用的状态了，失效的副本不会自动转移到其它可用的节点上，这会影响到系统整体可靠性和可用性。因此就需要进行分区重
分配来将分区副本迁移到可用节点上




日志存储：

    日志文件布局：
        主题 -> 对应多个分区 -> 对应多个副本 -> 对应一个日志目录(一个分区副本) -> 对应多个日志分段(LogSegment) ->↓ 
    对应一个日志文件(.log)、偏移量索引文件(.index)、时间戳索引文件(.timeindex)、以及其它文件

    日志目录所在与格式：
        一般会在kafka安装目录所在盘的/tmp/kafka-logs，命名方式为topic-partition


        kafka向Log中追加消息时是顺序写入的，每个日志目录，也就是分区副本中，只有最后一个LogSegment才能被执行写入操作，
    其余同分区中的所有LogSegment都不能写入数据。最后一个LogSegment称为activeSegment，既活跃的日志分段。随着消息的不断写
    入，当activeSegment满足一定条件时，就需要创建新的activeSegment，之前activeSegment不再是活跃分段，之后追加的消息都将
    写入新的activeSegment

        每个LogSegment中的日志文件都以.log作为文件后缀，每个.log文件都有对应的两个索引文件：.index与.timeindex，分别是
    偏移量索引与时间戳索引文件。每个LogSegment都有一个基准偏移量baseOffset用来表示当前LogSegment中第一条消息的偏移量。
    偏移量是一个64位的整型，日志文件和两个索引文件都是根据baseOffset命名的，名称固定为20位数字，比如每个分区的第一个日
    志文件名为：00000000000000000000.log，这代表该文件的偏移量是从0开始的。这个数字代表的是消息偏移量，而非字节数

        _consumer_offsets偏移量主题初始是不存在的，当第一次有消费者消费消息时会自动创建这个主题。每个kafka-logs根目录都
    会包含4个xxx-checkpoint检查点文件与一个meta.properties元数据文件，这些文件会在kafka服务第一次启动时创建


    日志格式：
        kafka消息从0.8.x之后到现在的2.0.0经历了3个版本：v0、v1、v2，0.8之前的不用再管

        v0版本：
            消息分为两部分：
                LOG_OVERHEAD，即消息头，它包含了：
                    offset(8B)：消息偏移量
                    message size(4B)：消息大小

                RECORD，即消息本身，它包含了：
                    crc32：校验值，校验后面的所有其余信息，4B
                    magic：消息版本号，1B
                    attributes：低三位表示消息压缩类型比如NONE、GZIP、LZ4等，其余位保留，1B
                    key length：key的长度，-1为没有key，4b
                    key：key内容
                    value length：value的长度，-1为没有value，4B
                    value：value内容，也可能会为空，比如墓碑消息
            每个完整的消息都由LOG_OVERHEAD与RECORD两部分组成，由于它们之间总是一对，因此通常也罢它们看作是一条消息的整
        体，每个log文件都由多个这种格式的消息组成
            每个消息最小长度为：4+1+1+4+4=14B，也即v0版本中一条消息长度如果小于14B，就代表它是破损消息而被拒收。kafka保
        存时会在另外加上12B的LOG_OVERHEAD，假设发送一条key为key，value为value的消息，那log文件的大小就为34B=12+4+1+1+4+
        3+4+5，其中3和5分别是key与value的大小

        v1版本：
            v1版本相比v0版本，也就在每条消息的magic后面多了一个8B的时间戳，然后attributes的第4位用来存储时间戳的类型。
        0表示CreateTime，1表示LogAppendTime。这个类型由broker端的log.message.timestamp.type来配置，默认值为CreateTime，
        既生产者创建消息的时间戳，如果用户没有显式指定，那么生产者发送消息时会自动创建这个时间戳
            因此v1版本的消息会比v0版本的大8个字节

        v2版本：
            消息分为两部分：
                Record Batch Header，既批次头，它包含了：
                    first offset：当前消息批次的起始偏移量，8B
                    length：从partition leader epoch字段到整个批次末尾的长度，4B
                    partition leader epoch：分区leader纪元，可以看做分区leader的版本号或更新次数，4B
                    magic：消息格式版本号，1B
                    crc32：校验值，4B
                    attributes：消息属性，低三位代表压缩格式，第四位代表时间戳类型，第五位标识此批次是否处于事务中，第六
                位表示是否控制消息，2B
                    last offset delta：消息批次中最后一个记录的偏移量与first offset的差值，4B
                    first timestamp：消息批次中第一条记录的时间戳，8B
                    max timestamp：消息批次中最大的时间戳，一般情况下是指最后一个消息的时间戳，8B
                    producer id：生产者id，用来支持幂等和事务，8B
                    producer epoch：生产者纪元，用来支持幂等和事务，2B
                    first sequence：用来支持幂等和事务，4B
                    records count：消息批次中的消息个数，4B

                Records：既批次列表，每个批次包含了：
                    length：消息总长度，varint
                    attributes：弃用，但是还存在着，1B
                    timestamp delta：基于批次头时间戳的增量，varlong
                    offset delta：基于批次头偏移量的增量，varint
                    key length：key长度，varint
                    key：key内容
                    value length：value长度，varint
                    value：value内容
                    headers count：header数量，varint
                    headers：header内容
                        header key length：header key的长度
                        header key：header key内容
                        header value length：header value的长度
                        header value：header value的内容
                以上很多地方都采用了增量存储，因为增量配合着变长字段可以进一步节省占用的字节数

    变长字段：
        Varints是kafka从0.11.0版本引入的变长整型，它的作用是：例如value length是-1，原本需要用4个字节来保存，用了
    Varints之后就只需要1个字节来保存，数字越小越节省空间，不过Varints并非会一直节省空间，一个int32一般是4个字节，但是
    用了Varints后最长会占用5个字节，一个int64一般是8个字节，用了Varints后最长会占用10个字节
        不过kafka的使用场景一般length都会比较小，因此总是能节省到空间

    消息压缩：
        常见的压缩算法是数据量越大压缩效果越好，但是一条消息通常不会太大，这就导致了压缩效果不太好。而kafka实现压缩的方
    式是将多条消息一起进行压缩，这样可以保证较好的亚索效果。在一半情况下，生产者发送的压缩数据在broker端的存储时也是保
    持压缩状态的，消费者从服务端获取的也是压缩的消息，消费者处理消息时才会解压消息，这样就保持了生产端到消费端的压缩

        kafka日志使用哪种压缩方式是通过compression.type参数来决定的，默认值为producer，表示保留生产者使用的压缩方式，这
    个参数还可以设置为：GZIP、SNAPPY、LZ4这几种压缩算法，如果配置为uncompressed则表示不压缩

        消息集合被压缩后作为内层消息(inner message)存在，整个内层消息作为外层消息(wrapper message)的value，也就是说压缩
    后，整个压缩结果都作为一个新消息的value，这个消息的key是空的
        生产者在压缩消息时，会为内层每个消息创建一个LOG_OVERHEAD，其中Offset是从0开始的，这代表消息在内层消息里的位置
        而外层消息的偏移量会根据内层消息的数量来决定，例如：上条消息的偏移量为1024，而此次压缩了6条消息，那么外层消息的
    偏移量就是1030，再下条消息就是1031。所以外层消息保存的是内层消息里最后一条消息的绝对偏移量

        压缩消息是指compress message，kafka里还有另外一个compact message，是指日志清理时的压缩，不要搞混

    消息压缩时的timestamp与attributes字段处理：
        外层消息的时间戳处理：timestramp是CreateTime，那么取的是内层消息中最大的时间戳，如果是LogAppendTime，那么取的是
    Kafka服务器的时间戳。
        内层的时间戳处理：外层消息是CreateTime，取得是生产者创建消息时的时间戳；外层是LogAppendTime，内层的时间戳将会忽
    略
        auutibutes的处理：外层消息会根据配置设置，内层消息的时间戳类型位总是CreateTime，因为其它类型不会处理


日志索引：

    每个日志文件都对应两个索引文件，分别是：
        偏移量索引文件：
            用来建立消息偏移量到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置
        时间戳索引文件：
            时间戳索引文件则根据指定的时间戳来查找对应的偏移量信息

    稀疏索引：
        稀疏索引就是，并不会为每条消息构建一个索引，而是每当写入一定的数据量之后，偏移量与时间戳索引文件分别增加一
    个偏移量索引项和时间戳索引项，这取决于log.index.interval.bytes，默认为4096，既4K，增大该值可以减小索引的密度，
    反之亦然
        稀疏索引通过MappedByteBuffer将索引文件映射到内存中，MappedByteBuffer会通过内存映射的方式读写文件内容，
    这种方式直接调用系统底层，没有JVM和系统之间的复制操作，所以效率很高。
        
    kafka中的索引文件以稀疏索引的方式来构造消息的索引，以提高查询速度。偏移量索引文件中的偏移量时单调递增的，当
查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量
的最大偏移量；时间戳索引的查询方式与存储规则也跟偏移量基本一致
    稀疏索引是在磁盘空间、内存空间、查找时间多个方面之间的一个折中方案



















