
Kafka基本介绍：
    Kafka是一个分布式流处理平台

    Kafka通过topic对存储的流数据进行分类
    
    Kafka的每条记录都包含一个key、一个value、一个时间戳

    Kafka有4个核心API：
	Producer：提供者，发布流式数据到topic
	Consumer：消费者，订阅topic，对订阅到的流式数据进行处理
	Streams：流处理器，消费topic产生的输入流，再讲产生的结果输出到其它topic中去，作为输入输出之间的转换
	Connector：可重用的生产或消费者，将topics连接到已存在的应用或数据库，可以捕捉所有的内容变更

    每个topic都有多个分区日志，每个分区里的数据都是有序且不可变的，Kafka的每个分区添加数据都是不断追加到commit log  文件中，每条记录都会分配一个id表示顺序，这个id称为offset，offset是由消费者来控制的，消费者往往是线性的方式去增加  偏移量进行消费，消费者可以随意控制消费的offset，因此同一条记录可以被重复消费。Kafka有保留策略，比如设置为两天，那  么记 录发布两天就会被抛弃并释放磁盘空间
     日志中的分区可以在日志超过单台服务器限制时允许进行扩展，只要开新的分区就行了，还可以作为并行的单元集


kafka的消费者分组：
    kafka的消费者可以指定不同的分组，kafka会把相同topic的每个消息都发给所有相同topic分组，但是每个分组里只会有一个消费者能拿到消息
    每个消费者组的消费者数量不应大于分区数量，多余的消费者会永远消费不到消息，因为kafka的每个分区的消费顺序是能保证的，每个消费者组都会有一个自己的消息消费偏移量记录，因此可以理解为kafka能保证每个分区的消息在每个消费者组里的消费顺序。也就是消费者组里的某个消费者消费完之后才会更新偏移量这个偏移量记录在kafka。这就导致了只有一个分区，就算消费者组里有一百个消费者，那同时也只能有一个消费者在处理，因为要保证分区的顺序就只能单消费者，所以相同的分区在做负载均衡的时候会绑定某个消费者，总是把消息发给它，因为发给不同的消费者也要等前面的消费者处理完，那不停切换消费者反而更麻烦，其它消费者总是空闲的，性能不会有任何提升，因此消费者组里的消费者数量大于分区数量没有任何意义
    也就是kafka里的每个分区同时只会给每个消费组里的一个消费者处理，但是一个消费者可能会同时处理多个分区的消息。要保证顺序必须让相同的消费者总是处理同一个分区，同时处理多个分区也能保证，最高效率的做法就是每个消费者只处理一个分区的数据，kafka的负载均衡能将分区分摊到每个消费者上，如果消费者比分区少那就必然会有消费者同时处理多个分区，假如一个分区的同消费组里有两个消费者，那么有一个消费者永远拿不到消息，因为分区只会绑定一个消费者
    如果发一条消息想要有多个处理逻辑，并且是隔离的，那么可以在相同的topic下用多个消费组，因为每个消费组都有自己在每个分区的偏移量，因此能保证不同逻辑不会相互影响，也能保证不同逻辑的消息不会丢失，也能有自己独立的偏移量记录

Broker：
    每个broker存包含多个Topic，每个topic包含多个分区，broker就是一个集群的节点，每个分区可以在多个broker上有相同的副 本
    感觉跟es类似，每个broker都是一个集群节点，每个topic就是索引，每个分区就是分片，分区的副本就是分片的副本，每个分区都有一个leader进行这个分区的写入操作，其它副本记录冗余数据，多余的副本可以用来备份和查询，一旦某个分区的leader挂了，可以将该分区的其它副本升级为leader
    leader分区的写入方式分为两种，一种是写入leader的broker之后就立即返回发送成功，不过如果给副本分区发送失败，此时leader刚好又挂了就会出现消息丢失，另一种是写入leader之后再写入所有的副本才返回发送成功，这就能绝对保证消息不丢失，不过性能肯定会下降，因为要等待所有副本都写入完成，这方面就要看要性能还要是可靠性了
    RocketMQ还支持配置leader里写入内存就返回还是写入磁盘才返回，不知道kafka是否一样，同步刷盘异步刷盘，主从同步，每个不同主从又分同步刷盘异步刷盘，反正就是性能和可靠性的取舍
















