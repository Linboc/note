
Kafka基本介绍：
    Kafka是一个分布式流处理平台

    Kafka通过topic对存储的流数据进行分类
    
    Kafka的每条记录都包含一个key、一个value、一个时间戳

    Kafka有4个核心API：
	Producer：提供者，发布流式数据到topic
	Consumer：消费者，订阅topic，对订阅到的流式数据进行处理
	Streams：流处理器，消费topic产生的输入流，再讲产生的结果输出到其它topic中去，作为输入输出之间的转换
	Connector：可重用的生产或消费者，将topics连接到已存在的应用或数据库，可以捕捉所有的内容变更

    每个topic都有多个分区日志，每个分区里的数据都是有序且不可变的，Kafka的每个分区添加数据都是不断追加到commit log  文件中，每条记录都会分配一个id表示顺序，这个id称为offset，offset是由消费者来控制的，消费者往往是线性的方式去增加  偏移量进行消费，消费者可以随意控制消费的offset，因此同一条记录可以被重复消费。Kafka有保留策略，比如设置为两天，那  么记 录发布两天就会被抛弃并释放磁盘空间
     日志中的分区可以在日志超过单台服务器限制时允许进行扩展，只要开新的分区就行了，还可以作为并行的单元集


kafka的消费者分组：
    kafka的消费者可以指定不同的分组，kafka会把相同topic的每个消息都发给所有相同topic分组，但是每个分组里只会有一个消费者能拿到消息
    每个消费者组的消费者数量不应大于分区数量，多余的消费者会永远消费不到消息，因为kafka的每个分区的消费顺序是能保证的，每个消费者组都会有一个自己的消息消费偏移量记录，因此可以理解为kafka能保证每个分区的消息在每个消费者组里的消费顺序。也就是消费者组里的某个消费者消费完之后才会更新偏移量这个偏移量记录在kafka。这就导致了只有一个分区，就算消费者组里有一百个消费者，那同时也只能有一个消费者在处理，因为要保证分区的顺序就只能单消费者，所以相同的分区在做负载均衡的时候会绑定某个消费者，总是把消息发给它，因为发给不同的消费者也要等前面的消费者处理完，那不停切换消费者反而更麻烦，其它消费者总是空闲的，性能不会有任何提升，因此消费者组里的消费者数量大于分区数量没有任何意义
    也就是kafka里的每个分区同时只会给每个消费组里的一个消费者处理，但是一个消费者可能会同时处理多个分区的消息。要保证顺序必须让相同的消费者总是处理同一个分区，同时处理多个分区也能保证，最高效率的做法就是每个消费者只处理一个分区的数据，kafka的负载均衡能将分区分摊到每个消费者上，如果消费者比分区少那就必然会有消费者同时处理多个分区，假如一个分区的同消费组里有两个消费者，那么有一个消费者永远拿不到消息，因为分区只会绑定一个消费者
    如果发一条消息想要有多个处理逻辑，并且是隔离的，那么可以在相同的topic下用多个消费组，因为每个消费组都有自己在每个分区的偏移量，因此能保证不同逻辑不会相互影响，也能保证不同逻辑的消息不会丢失，也能有自己独立的偏移量记录

Broker：
    每个broker存包含多个Topic，每个topic包含多个分区，broker就是一个集群的节点，每个分区可以在多个broker上有相同的副本
    感觉跟es类似，每个broker都是一个集群节点，每个topic就是索引，每个分区就是分片，分区的副本就是分片的副本，每个分区都有一个leader进行这个分区的写入操作，其它副本记录冗余数据，多余的副本可以用来备份和查询，一旦某个分区的leader挂了，可以将该分区的其它副本升级为leader
    leader分区的写入方式分为两种，一种是写入leader的broker之后就立即返回发送成功，不过如果给副本分区发送失败，此时leader刚好又挂了就会出现消息丢失，另一种是写入leader之后再写入所有的副本才返回发送成功，这就能绝对保证消息不丢失，不过性能肯定会下降，因为要等待所有副本都写入完成，这方面就要看要性能还要是可靠性了
    RocketMQ还支持配置leader里写入内存就返回还是写入磁盘才返回，不知道kafka是否一样，同步刷盘异步刷盘，主从同步，每个不同主从又分同步刷盘异步刷盘，反正就是性能和可靠性的取舍


消息的幂等性：
    重复发送：由于消息发送可能会失败，很多mq都有重试机制，导致有重复消息。可以每次发送消息先生成一个消息id，消息发送时带着这个id，假如某次mq服务器收到消息并处理好，向客户端没收到响应，然后客户端重发，那么mq服务器可以校验这个消息id是否已存在来决定重发的消息处不处理。客户端每次发消息都会申请一次id，同一次发送的自动重发这个id都会一样

    重复消费：由于ack是客户端处理完业务手动调用，可能业务事务结束后提交了，ack却失败了，或者ack成功，事务却失败了，可以在事务里加一个日志记录表记录所有处理过的消息，消费前先判断表里有没有消费过这条消息，没有才走消费逻辑

kafka生产者配置：
    bootstrap.servers：kafka的服务器和端口
    acks：是否要判断是否发送成功，如果指定了all，每次发消息都会阻塞，等收到服务器的确认后才发下一个，性能低但可靠
    retries：如果发送失败是否要进行重试，如果重试则会有重复消息的可能
    batch.size：缓存每个区未发送的消息大小，包括消息头元数据和消息体，kafka客户端不是收到消息马上就发送，而是达到batch.size指定的缓冲区大小才一起发送，所以应该在关闭生产者时进行生产者close，每个活跃的分区都有一个缓冲区
    linger.ms：缓冲区没满的情况下多久后发送，可能消费者迟迟达不到batch.size，导致消息不发送，这时就需要一个配置来决定多久后发送缓冲区里的数据，那就是linger.ms，如果linger.ms=0就总是马上发送，如果在高负载的情况下，即使linger.ms=0时间相近的消息也会组成批
    buffer.memory：生产者的缓存总量，也就是所有分区的batch.size加起来不能超过buffer.memory
    key.serializer：key的序列化方式，有简单的StringSerializer和ByteArraySerializaer可以使用
    value.serializer：value的序列化方式
    enable.idempotence：启用幂等，在幂等的情况下，acks默认为all，retries默认为Integer.MAX_VALUE，也就是每条消息必等服务器确认且无限重试
    transactional.id：使用事务生产者，指定后会自动启用幂等与其相关配置，所有的事务相关API都是阻塞的，并且在失败时抛出异常，所以应该在catch中进行事务回滚，producer.initTransactions()：生产者初始化事务配置，producer.beginTransaction();：生产者开始事务，producer.commitTransaction()，生产者提交事务，producer.abortTransaction()：生产者回滚事务

send()：
    kafka消息发送的方法，send方法可以只指定一个参数：ProducerRecord，这样send就会返回一个Future，如果手动调用Future的get就会阻塞，也可以传两个参数，第二个参数传Callback，消息发送成功后就会进行回调，发送的结果是RecordMetadata，它里面包含了消息的分区、分配的offset和消息的时间戳，发送给相同分区的消息一定是有序的
    由于Callback的回调线程是kafka客户端的I/O线程，如果处理回调太久会影响到kafka的性能，如果回调处理得的话可以在Callback里使用自己的Executor(线程池)来处理

kafka消费者配置：
    group.id：消费者组id，每个topic下的每条消息都会给所有消费者组的某个消费者发送一次
    enable.auto.commit：是否启用自动提交，默认开启
    auto.commit.interval.ms：自动提交的频率，默认5000，也就是默认情况下偏移量5000ms后会被kafka更新，实测就算不到时间也会被更新
    max.poll.interval.ms：消费者拉消息的频率
    max.poll.records：消费者拉消息的间隔
    session.timeout.ms：消费者的最长心跳间隔，如果超过这个间隔没有心跳服务器会将分区分配给其它同组的消费者










