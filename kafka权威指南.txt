发布与订阅消息系统：
    数据的发送者不会直接把消息发送给接收者，而是对消息进行分类，然后接受者订阅特定类型的消息，这是发布与订阅消息系
统的特点。发布与订阅系统一般会有一个broker，也是发布消息的中间点，broker主要用来分发消息，也可以提供一些额外的功
能，比如延迟发送

kafka的消息简介：
    kafka的消息有一个可选的元数据，也就是键。键与消息一样也是一个字节数组，当需要消息以一种可控的方式写入不同分区时
，就会用到键，最简单的就是用键生成HashCode，然后对分区数进行取模，为消息分区，这样保证了相同键的消息总是被写到相
同的分区上

kafka的批次简介：
    为了提高效率，消息被分批次写入kafka，批次就是一组消息，这些消息属于同一个主题和同一个分区，如果每个消息都单独穿
行于网络，会导致大量网络开销。
    把消息分成批次传输可以减少网络开销，不过会造成延迟，所以需要在延迟与吞吐量之间做出权衡。批次越大，单位时间内处
理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据传输与存储能力，但要做更多计算处理


消息模式简介：
    消息不过是晦涩难懂的字节数组，消息模式可以以特定的结构来定义消息内容，比如JSON和XML。其实模式指的就是序列号方
式。模式与消息是分开的，当模式发生变化时，不需要重新生成代码

主题和分区简介：
    kafka的消息通过主题进行分类。主题就好比数据库的表，或文件系统的文件夹。主题可以被氛围若干个分区，一个分区就是一
个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取
    由于一个主题包含多个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序
    kafka通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说一个主题可以横跨多个服务器，以此来提
供比单个服务器更强大的性能
    我们通常会用流这个词来描述kafka这类系统的数据

生产者和消费者简介：
    生产者创建消息，一般情况下，一个消息会被发布到一个特定的主题上。
    生产者在默认情况下会把消息均衡地分布到主题的所有分区上，而不关心消息会被写到哪个分区。不过如果指定了分区键和分
区器，生产会把消息写到指定的分区，分区器会为键生成一个散列值，并将其映射到指定的分区上。这样保证了同一个键会被写到
同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区
    消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。
    消费者通过检查消息的偏移量来区分已经读取过的消息，偏移量是一个不断递增的整数值，在一个分区里，每个消息的偏移量
都是唯一的。消费者把每个分区最后读取的消息偏移量保存在zookeeper或kafka上，保证消费者关闭或重启后，读取状态不丢失
    消费者是消费者组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用，
但是一个消费者可以同时消费多个分区，因为这样才能保证消息消费的顺序
    如果一个消费者失效，群组里的其它消费者可以接管失效消费者的工作，也就是去接手消费它的分区

broker和集群简介：
    一个独立的kafka服务器被称为broker。broker接受来自生产者的消息，为消息设置偏移量，并将消息保存到磁盘。broker为
消费者提供服务，对读取分区的请求做出响应，返回磁盘上已提交的消息。根据特定的硬件与性能特征，单个broker可以轻松处理
数千个分区以及每秒百万级的消息量
    broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色，这个角色是自动选举出来的。控制器负责
管理工作，包括将分区分配给broker和监控broker。
    在集群中，一个分区属于一个broker，该broker称为该分区的首领。一个分区可以分配给多个broker，此时会发生分区复制，
这种复制机制为分区提供了消息冗余，如果某个分区的首领broker失效了，其它broker可以接管该分区的领导权，不过生产者和
消费者都要连接到新的首领broker

保留消息：
    kafka broker的消息保留策略是：要么保留一段时间(比如7天)，要么在保留消息的字节数达到一定大小(比如1G)。当消息达到
上限时，旧消息就会过期并被删除
    每个主题都可以配置自己的保留策略。也可以通过配置将主题当做紧凑型日志，紧凑型日志只会为每个不同的键保留最后一条
变更的消息

多集群：
    随着kafka部署数量的增加，基于以下原因，最好使用多个集群：
        1、数据类型分离
        2、安全需求隔离
        3、多数据中心(灾难恢复)
    多个数据中心之间，如果要保证数据一致，就需要在它们之间复制消息。不过kafka的消息复制机制只能在单个集群里进行，不
能在多个集群之间进行
    不过kafka提供了一个叫做MirrorMaker的工具，它可以实现集群间的消息复制。MirrorMaker的核心组件包含了一个生产者和
一个消费者，两者通过一个队列连接。消费者从一个集群中读取消息，生产者再把消息发送到另一个集群上。
    比如，多个Kafka集群都先用MirrorMaker的消费者消费消息，然后用生产者发送到另一个统一聚合集群里，然后将这个聚合集
群的消息再用相同的方式复制到另一个数据中心即可

kafka中的zookeeper：
    在kafka中，zookeeper的作用主要是保存broker、主题、消费者的元数据与消费者的分区偏移量

    zookeeper集群：
        关于zookeeper的作用与选举的相关知识，可以看zookeeper.txt，这里介绍zookeeper集群的配置：
        zookeeper群组不建议超过7个，因为zookeeper使用了一致性协议，节点太多会降低性能，如果希望在线更新zookeeper的
    配置，可以修改后依次重启每个节点，既能高可用又能改到配置
        每个zookeeper服务器还要在数据目录中创建一个myid文件，用于指明自己的服务器id，文件内容如下：
            tickTime=2000：指定基础的时间单位，与其它时间配置配合使用
            dataDir=/var/lib/zookeeper：zookeeper的目录
            clientPort=2181：客户端端口，专门给客户端api使用的端口
            initLimit=20：从节点与主节点建立初始化连接的时间上限，20的意思是(tickTime的20倍)毫秒
            syncLimit=5：允许从节点与主节点不同步状态的时间上限，5的意思是(tickTime的5倍)毫秒
            server.1=zoo1.boc.com:2888:3888
            server.2=zoo2.boc.com:2888:3888
            以上两行配置：server.是固定值；1代表服务器id，必须是整数，不能重复，此id要与zookeeper的配置文件id一直，其它
        没要求；zoo1.boc.com是服务器名或ip；2888是用于节点之间通信的端口；3888是用于leader选举通信的端口

broker：
    broker.id：
        每个broker都需要有一个唯一标识，默认值是0，可以设置成任何整数，这个值在集群中必须唯一

    port：
        kafka默认端口是9092，如有需要可以自行修改

    zookeeper.connect：
        zookeeper的连接地址，默认是localhost:2181，可以指定多个，用分号分隔，这样如果某个zookeeper挂了可以连其他的
        比如localhost:2181/kafka;localhost:2182/kafka，后面的kafka是broker在zookeeper中的根路径，默认为/

    log.dirs：
        保存消息的路径，多个用逗号分隔，如果指定多个，broker会保证相同分区的日志片段保存到相同的路径，新的分区会根据
    最小分区原则选择路径，也就是哪个路径的分区最少就选哪个

    num.recovery.thread.pre.data.dir：
        kafka启动和停止时的线程数
        对于一下3种情况，kafka会使用线程池来处理日志：
            1、服务器启动时，用于打开每个分区的日志片段
            2、服务器奔溃后重启，用于检查和截短每个分区的日志片段
            3、服务器关闭时，用于关闭日志片段
        默认情况下，每个日志目录只是用一个线程，线程池只是在服务器启动和关闭时用来加速用的
        如果这个值设置为8，代表每个目录需要8个线程，此时如果log.dirs又有3个目录，那么一共需要8*3=24个线程

    auto.create.topics.enable：
        kafka是否自动创建topic，以下几种情况会自动创建topic：
            1、生产者往主题写入消息
            2、消费者从主题读消息
            3、客户端向主题发送元数据相关请求


主题的配置：
    num.partittons：
        自动创建主题时的分区数量

    log.retention.ms：
        数据可以被保留的时间，单位为毫秒
    log.retentoin.minutes：
         数据可以被保留的时间，单位为分钟
    log.retentoin.hours：
         数据可以被保留的时间，单位为小时，默认值为168，也就是一周
    以上几个数据保留时间配置，当多个同时存在时，以最小值的为准
    注意，以上几个配置都是以日志片段的最后更新时间为准，一个日志片段就是一个文件，也就是说，如果日志片段10天才写满，
那么过期时间将从第十天开始算

    log.retenion.bytes：
        每个分区的数据最多可以被保留的字节数，单位为字节，如果和log.retention.ms同时指定，则满足任意一个就会删除消息

    log.segment.bytes：
        日志片段的大小，单位为字节，默认为1G，到时间后日志片段将被关闭。如果太大就会影响到数据过期时间，根据时间戳获
    取偏移量等操作，因为它们都是基于日志片段的信息来计算的
        比如根据时间戳获取偏移量，kafka会找到分区里最后修改时间大于指定时间戳的日志片段(已被关闭的)，然后返回该日志片
    段的开头偏移量，日志片段也小准确度越高

    log.segment.ms：
        日志片段被关闭的时间，单位为毫秒，默认不开启。与log.segment.bytes之间任意一个满足条件就会关闭日志片段。日志片
    段的过期时间是从broker启动之后开始计算的

    message.max.bytes：
        单个消息的大小限制，默认值是1000000，也就是1MB。如果超过broker会返回报错信息，该参数计算的是消息被压缩后的
    大小















































