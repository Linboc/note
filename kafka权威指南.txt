发布与订阅消息系统：
    数据的发送者不会直接把消息发送给接收者，而是对消息进行分类，然后接受者订阅特定类型的消息，这是发布与订阅消息系
统的特点。发布与订阅系统一般会有一个broker，也是发布消息的中间点，broker主要用来分发消息，也可以提供一些额外的功
能，比如延迟发送

kafka的消息简介：
    kafka的消息有一个可选的元数据，也就是键。键与消息一样也是一个字节数组，当需要消息以一种可控的方式写入不同分区时
，就会用到键，最简单的就是用键生成HashCode，然后对分区数进行取模，为消息分区，这样保证了相同键的消息总是被写到相
同的分区上

kafka的批次简介：
    为了提高效率，消息被分批次写入kafka，批次就是一组消息，这些消息属于同一个主题和同一个分区，如果每个消息都单独穿
行于网络，会导致大量网络开销。
    把消息分成批次传输可以减少网络开销，不过会造成延迟，所以需要在延迟与吞吐量之间做出权衡。批次越大，单位时间内处
理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据传输与存储能力，但要做更多计算处理


消息模式简介：
    消息不过是晦涩难懂的字节数组，消息模式可以以特定的结构来定义消息内容，比如JSON和XML。其实模式指的就是序列号方
式。模式与消息是分开的，当模式发生变化时，不需要重新生成代码

主题和分区简介：
    kafka的消息通过主题进行分类。主题就好比数据库的表，或文件系统的文件夹。主题可以被氛围若干个分区，一个分区就是一
个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取
    由于一个主题包含多个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序
    kafka通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说一个主题可以横跨多个服务器，以此来提
供比单个服务器更强大的性能
    我们通常会用流这个词来描述kafka这类系统的数据

生产者和消费者简介：
    生产者创建消息，一般情况下，一个消息会被发布到一个特定的主题上。
    生产者在默认情况下会把消息均衡地分布到主题的所有分区上，而不关心消息会被写到哪个分区。不过如果指定了分区键和分
区器，生产会把消息写到指定的分区，分区器会为键生成一个散列值，并将其映射到指定的分区上。这样保证了同一个键会被写到
同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区
    消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。
    消费者通过检查消息的偏移量来区分已经读取过的消息，偏移量是一个不断递增的整数值，在一个分区里，每个消息的偏移量
都是唯一的。消费者把每个分区最后读取的消息偏移量保存在zookeeper或kafka上，保证消费者关闭或重启后，读取状态不丢失
    消费者是消费者组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用，
但是一个消费者可以同时消费多个分区，因为这样才能保证消息消费的顺序
    如果一个消费者失效，群组里的其它消费者可以接管失效消费者的工作，也就是去接手消费它的分区

broker和集群简介：
    一个独立的kafka服务器被称为broker。broker接受来自生产者的消息，为消息设置偏移量，并将消息保存到磁盘。broker为
消费者提供服务，对读取分区的请求做出响应，返回磁盘上已提交的消息。根据特定的硬件与性能特征，单个broker可以轻松处理
数千个分区以及每秒百万级的消息量
    broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色，这个角色是自动选举出来的。控制器负责
管理工作，包括将分区分配给broker和监控broker。
    在集群中，一个分区属于一个broker，该broker称为该分区的首领。一个分区可以分配给多个broker，此时会发生分区复制，
这种复制机制为分区提供了消息冗余，如果某个分区的首领broker失效了，其它broker可以接管该分区的领导权，不过生产者和
消费者都要连接到新的首领broker

保留消息：
    kafka broker的消息保留策略是：要么保留一段时间(比如7天)，要么在保留消息的字节数达到一定大小(比如1G)。当消息达到
上限时，旧消息就会过期并被删除
    每个主题都可以配置自己的保留策略。也可以通过配置将主题当做紧凑型日志，紧凑型日志只会为每个不同的键保留最后一条
变更的消息

多集群：
    随着kafka部署数量的增加，基于以下原因，最好使用多个集群：
        1、数据类型分离
        2、安全需求隔离
        3、多数据中心(灾难恢复)
    多个数据中心之间，如果要保证数据一致，就需要在它们之间复制消息。不过kafka的消息复制机制只能在单个集群里进行，不
能在多个集群之间进行
    不过kafka提供了一个叫做MirrorMaker的工具，它可以实现集群间的消息复制。MirrorMaker的核心组件包含了一个生产者和
一个消费者，两者通过一个队列连接。消费者从一个集群中读取消息，生产者再把消息发送到另一个集群上。
    比如，多个Kafka集群都先用MirrorMaker的消费者消费消息，然后用生产者发送到另一个统一聚合集群里，然后将这个聚合集
群的消息再用相同的方式复制到另一个数据中心即可

kafka中的zookeeper：
    在kafka中，zookeeper的作用主要是保存broker、主题、消费者的元数据与消费者的分区偏移量

    zookeeper集群：
        关于zookeeper的作用与选举的相关知识，可以看zookeeper.txt，这里介绍zookeeper集群的配置：
        zookeeper群组不建议超过7个，因为zookeeper使用了一致性协议，节点太多会降低性能，如果希望在线更新zookeeper的
    配置，可以修改后依次重启每个节点，既能高可用又能改到配置
        每个zookeeper服务器还要在数据目录中创建一个myid文件，用于指明自己的服务器id，文件内容如下：
            tickTime=2000：指定基础的时间单位，与其它时间配置配合使用
            dataDir=/var/lib/zookeeper：zookeeper的目录
            clientPort=2181：客户端端口，专门给客户端api使用的端口
            initLimit=20：从节点与主节点建立初始化连接的时间上限，20的意思是(tickTime的20倍)毫秒
            syncLimit=5：允许从节点与主节点不同步状态的时间上限，5的意思是(tickTime的5倍)毫秒
            server.1=zoo1.boc.com:2888:3888
            server.2=zoo2.boc.com:2888:3888
            以上两行配置：server.是固定值；1代表服务器id，必须是整数，不能重复，此id要与zookeeper的配置文件id一直，其它
        没要求；zoo1.boc.com是服务器名或ip；2888是用于节点之间通信的端口；3888是用于leader选举通信的端口

broker：
    broker.id：
        每个broker都需要有一个唯一标识，默认值是0，可以设置成任何整数，这个值在集群中必须唯一

    port：
        kafka默认端口是9092，如有需要可以自行修改

    zookeeper.connect：
        zookeeper的连接地址，默认是localhost:2181，可以指定多个，用分号分隔，这样如果某个zookeeper挂了可以连其他的
        比如localhost:2181/kafka;localhost:2182/kafka，后面的kafka是broker在zookeeper中的根路径，默认为/

    log.dirs：
        保存消息的路径，多个用逗号分隔，如果指定多个，broker会保证相同分区的日志片段保存到相同的路径，新的分区会根据
    最小分区原则选择路径，也就是哪个路径的分区最少就选哪个

    num.recovery.thread.pre.data.dir：
        kafka启动和停止时的线程数
        对于一下3种情况，kafka会使用线程池来处理日志：
            1、服务器启动时，用于打开每个分区的日志片段
            2、服务器奔溃后重启，用于检查和截短每个分区的日志片段
            3、服务器关闭时，用于关闭日志片段
        默认情况下，每个日志目录只是用一个线程，线程池只是在服务器启动和关闭时用来加速用的
        如果这个值设置为8，代表每个目录需要8个线程，此时如果log.dirs又有3个目录，那么一共需要8*3=24个线程

    auto.create.topics.enable：
        kafka是否自动创建topic，以下几种情况会自动创建topic：
            1、生产者往主题写入消息
            2、消费者从主题读消息
            3、客户端向主题发送元数据相关请求


主题的配置：
    num.partittons：
        自动创建主题时的分区数量

    log.retention.ms：
        数据可以被保留的时间，单位为毫秒
    log.retentoin.minutes：
         数据可以被保留的时间，单位为分钟
    log.retentoin.hours：
         数据可以被保留的时间，单位为小时，默认值为168，也就是一周
    以上几个数据保留时间配置，当多个同时存在时，以最小值的为准
    注意，以上几个配置都是以日志片段的最后更新时间为准，一个日志片段就是一个文件，也就是说，如果日志片段10天才写满，
那么过期时间将从第十天开始算

    log.retenion.bytes：
        每个分区的数据最多可以被保留的字节数，单位为字节，如果和log.retention.ms同时指定，则满足任意一个就会删除消息

    log.segment.bytes：
        日志片段的大小，单位为字节，默认为1G，到时间后日志片段将被关闭。如果太大就会影响到数据过期时间，根据时间戳获
    取偏移量等操作，因为它们都是基于日志片段的信息来计算的
        比如根据时间戳获取偏移量，kafka会找到分区里最后修改时间大于指定时间戳的日志片段(已被关闭的)，然后返回该日志片
    段的开头偏移量，日志片段越小准确度越高

    log.segment.ms：
        日志片段被关闭的时间，单位为毫秒，默认不开启。与log.segment.bytes之间任意一个满足条件就会关闭日志片段。日志片
    段的过期时间是从broker启动之后开始计算的

    message.max.bytes：
        单个消息的大小限制，默认值是1000000，也就是1MB。如果超过broker会返回报错信息，该参数计算的是消息被压缩后的
    大小


kafk的硬件关注点：
    磁盘的吞吐量(影响生产者，磁盘写入越快，生产者提交就越快)、磁盘容量(影响需要保留的数量量)、内存(影响消费者，消息会
放在系统页面缓存，或者缓存消息片段)、网络(虽然也重要，但与机器本身无关)、CPU(压缩和解压，kafka对这方面要求不高)


broker集群的基本配置：
    zookeeper.connect：
        zookeeper的群组和路径
        broker.id：每个broker中的id再集群里必须唯一

生产者：

    消息生产概览：
        1、创建一个ProducerRecord对象，其中包含了主题、消息内容、键、分区
        2、生产者把键和值对象序列化成字节数组
        3、数据传给分区器，如果ProducerRecord指定了分区，分区器就不会做任何事，否则分区器会根据ProducerRecord的键
    来指定一个分区
        4、这条记录被添加到一个记录批次里，这个批次里的所有消息都是同样的主题和分区
        5、有一个独立的线程负责把这些记录批次发送到对应的beoker上
        6、如果消息成功写入Kafka，就返回一个RecordMetaData对象，它包含了主题和分区的信息，以及消息在分区中的偏移量
        7、如果消息写入失败，就会返回一个错误，生产者收到错误后会尝试重复发送消息，如果多次后依然失败，就返回错误消息

    生产者对象属性：
        bootstrap.servers：
            必填，指定broker地址清单，地址格式为host:port，多个地址用逗号分割。清单里不需要包含所有broker地址，生产者
        会从给定的broker里找到其它broker的信息。不过建议多提供几个，以便其中某些宕机，生产者依然能从剩余的broker地址
        里连接到集群上

        key.serializer：
            必填，key的序列化类，必须实现org.apache.kafka.common.serialization.Serializer接口，生产者会使用这个类把键序
        列化成字节数组。kafka默认提供了ByteArraySerializer、Stringserializer、IntergerSerializer

        value.serializer：
            必填，与key.serializer一样，描述请参考key.serializer

        acks：
            指定必须有多少个分区副本收到消息，生产者才认为消息写入是成功的
            acsk=0：则生产者不等待服务器的响应，如果丢失了消息生产者也无从得知，当然，这样吞吐量也是最高的
            acks=1：只要集群里目标分区的首领节点收到消息，生产者就会收到服务器的成功响应。否则就会收到错误响应，如果收
        到了错误响应，生产者会重发消息。
            acks=all：当所有参与复制的分区节点都收到消息时，生产者才会收到服务器的成功响应。这种模式是最安全的，不过延
        迟也比较高

        buffer.memory：
            设置生产者内存缓冲区的大小，用来缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度
        ，导致生产者缓冲区空间不足，这时候send方法会被阻塞或者抛出异常

        max.block.ms：
            与buffer.memory有关，它用来表示当生产者缓冲区不足的时候，再抛出异常之前可以阻塞的时间，当超过阻塞时间依然
        空间不足才会抛出异常

        compression.type：
            消息压缩方式，默认情况下消息发送时不会被压缩。该参数可以设置为：snappy、gzip、lz4。指定消息在发送到broker
        之前使用哪种压缩算法。snappy比较均衡，CPU占用不高，压缩比也还可以，gzip的CPU占用较高，但压缩比也更高

        retries：
            重发消息的次数，服务器返回的错误可能是临时性的，必须分区在选举首领。这种情况下重发就可能会成功

        retry.backoff.ms：
            重发消息的间隔

        batch.size：
            当多个消息需要发送到相同的分区时，生产者会把他们放到同一个批次里。该参数指定了一个批次的内存大小，按字节计
        算。当批次被填满时，批次里所以消息都会被发送出去

        linger.ms：
            批次发送前等待的毫秒数，如果时间到了，批次还没满，生产者也会吧消息发出去，哪怕只有一个消息

        client.id：
            服务器用来识别消息的来源，可以用在日志和配额指标里

        max.in.flight.requests.pre.connection：
            指定了生产者在收到服务器响应之前可以发送多少个消息。值越高就会占用越多内存。值为1就能保证消息的顺序，哪怕
        发生了重试。如果大于1，可能同时发两条，第一条消息失败，第二条成功，第一条再重试，顺序就颠倒了

        timeout.ms：
            指定等待同步副本返回消息的确认时间，如果指定时间内没收到同步副本的确认，broker就会返回错误。broker会不会等
        待同步副本返回消息取决于acks的配置

        metadata.fetch.timeout.ms：
            生产者获取元数据时(比如分区受理是谁)，等待服务器返回响应的时间，如果超过指定时间则抛异常

        request.timeout.ms：
            生产者在发送数据时等待服务器返回的响应时间，如果超过指定时间则抛异常

        max.block.ms：
            调用send方法或者用partitionsFor方法获取元数据时生产者的阻塞时间。当生产者发送缓冲区已满或者没有可用元数据时
        ，这些方法就会阻塞。如果阻塞时间达到指定时间生产者就会抛出异常

        max.request.size：
            控制生产者发送的请求大小。可以指定单个消息的最大值，也可以用来指定单个请求里所有消息的总大小，比如1MB。
        broker那边也可以配置message.max.bytes对消息进行限制，两边最好可以匹配，避免生产者的消息被拒绝

        receive.buffer,bytes：
            TCP接受数据包的缓冲区大小，如果为-1则使用操作系统的默认值

        send.buffer.bytes：
            TCP发送数据包的缓冲区大小，如果为-1则使用操作系统的默认值

    发消息方法：
        发送并忘记：
            producer.send(record)，发送后就不管了
        同步发送：
            producer.send(record)会返回一个Future对象，只要马上就调future.get()进行等待，就是同步了
        异步发送：
            producer.send(record, callback)，kafka在收到broker的响应后会异步回调callback的代码，这个回调可能会包含异常
        信息，异步发送很适合在不需要kafka响应时使用，这样只发消息不等待响应，比发消息后等待响应所需的时间少很多

    生产者的异常：
        可重试错误：
            这类错误可通过重发消息来解决，比如：连接错误、no leader错误，kafka生产者可以被配置成自动重试，如果多次重试
        都无法解决问题，就会抛出重试异常

        不可重试错误：
            这类消息无法通过重试解决，比如消息太大异常，这类错误kafka不会进行重试，而是直接抛异常

    生产者在不使用时记得flush或者close，否则由于消息是分批发送的，如果刚发完生产者还没发送进程就结束了，就会导致消息
丢失


序列化器：

    虽然有很多不同类型的序列化器，不过基本都是用JSON转字符串后，再用StringSerializer

    书里还提供了Avro序列化框架的示例，不过还要另外搞一个服务器来提供不同的类型版本，比较麻烦


分区：

    默认分区器对key使用散列算法进行分区，如果没有key就随机分区

    自定义分区器：
        实现Partitioner接口然后在partition方法返回想指定的分区，configure传入生产者的配置，close在生产者关闭时调用


消费者和消费者组：

    Kafka消费者属于消费者组，一个群组里的消费者订阅的是同一个主题，其中的每一个消费者接受主题的一部分分区的消息。如
果一个群组里有多个消费者，那么主题的分区将会被组里的消费者平分，每个分区在一个消费者组里最多同时被一个消费者进行消
费。也就是如果消费者组的消费者数量比分区多，那么有部分消费者就会被闲置

    每个消费者组都能读到主题的全部消息

    分区再均衡：
        一个新的消费者加入群组时，它读取的是原本其它消费者读取的消息。一个消费者被关闭或者发生崩溃时，它读取的分区将
    由其它消费者来读取。
        分区的消费权从一个消费者转移到另一个消费者，这种行为被称为再均衡。再均衡为消费者群组带来了高可用性和伸缩性，
    不过在再均衡期间，消费者无法读取消息，会造成群组一小段时间不可用。另外，当分区被重新分配给另一个消费者时，消费
    者当前的读取状态会丢失，可能还要去刷新缓存来恢复状态
        消费者通过被指派为群组协调器的broker发送心跳来维持他们对分区的所有权与它们跟群组的从属关系。只要消费者以正常
    的时间间隔发送心跳，就被认为是活跃的。消费者会在轮询消息或提交偏移量时发送心跳。当消费者停止发送心跳的时间足够
    长，群组协调器就会认为它已死亡，此时会触发一次再均衡

    分配分区过程：
        1、消费者向群组协调器发送一个JoinGroup请求，第一个加入的消费者将成为群主
        2、群主从协调器那里获取群组的成员列表，群组列表包含最近发送过心跳的消费者。并负责给每一个消费者分配分区。分区
    分配使用ConsumerPartitionAssignor接口的实现类进行，旧版是PartitionAssignor（已废弃）
        3、群主分配完毕后会把分配情况发给群组协调器，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的消费
    信息，只有群主知道群组里所有消费者的分配信息，这个行为会在每次在均衡时重复发生

消费者参数：

    bootstrap.servers：
        制定多个broker地址，语义和生产者的同名属性相同

    key.deserializer：
        key的反序列化类，实现于Deserializer接口

    value.deserializer：
        value的反序列化类，实现于Deserializer接口

    group.id：
        指定消费者组

    fetch.min.bytes：
        指定消费者从服务器获取记录的最小字节数。broker会在收到消费者的数据请求时，如果可用的数据量小于fetch.min.bytes
    时，会等到有足够的数据才返回给消费者。这可以降低消费者和broker的负载，如果数据不多，但消费者CPU使用率很高，那
    就可以把这个参数设置的比默认值大

    fetch.max.wait.ms：
        指定broker的等待时间，默认是500ms。如果kafka流入的数据满足不了fetch.min.bytes，那么最多导致fetch.max.wait.ms
    的延迟。
        可以将fetch.min.bytes指定的高一些，比如1MB，fetch.max.wait.ms指定的低一些，比如100ms，将CPU使用率和消息延
    迟控制在一个可接受的范围。这样数据要么满足1MB，要么等到100ms，满足任一个都会返回

    max.partition.fetch.bytes：
        指定了服务器从每个分区里返回给消费者的最大字节数。默认值是1MB，kafkaConsumer.poll()方法从每个分区里返回的记
    录最多不超过max.partition.fetch.bytes指定的字节。
        如果一个主题有20个分区，5个消费者，那么每个消费者至少要有4MB的内存来接收记录，而且还要考虑其它消费者崩溃发
    生再均衡，导致剩下的消费者需要处理更多分区
        max.partition.fetch.bytes一定要比max.message.size大，否则如果单条消息就超过了max.partition,fetch.bytes，那么这
    条消息就可能无法成功读取，导致消费者一直挂起重试
        还要考虑如果max.partition.fetch.bytes太大会导致消息过多，消费者无法及时调用下次poll()来避免会话过期，如果出现这
    种情况可以改小改值，或者延长会话时间

    session.timeout.ms：
        指定了消费者在被认为死亡前可以与服务器断开连接的时间，也就是最长心跳间隔，默认是3s。
        如果消费者没有在session.time.out指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，将它
    的分区分配给其它消费者。
        session.timeout.ms一般与hearbeat.interval.ms配合使用
        session.timeout.ms设置的比较小可以更快地检测和恢复崩溃的节点。不过长时间的轮询和GC可能会导致预料之外的再均衡
    ，所以大一些可以避免意外情况。根据具体场景去选择

    hearbeat.interval.ms：
        指定poll()方法向协调器发送心跳的频率，一般是session.timeout.ms的三分之一，必须小于session.timeout.ms

    auto.offset.reset：
        指定消费者在读取一个没有偏移量的分区，或者偏移量无效(消费者长时间失效，偏移量的记录已被删除)的情况下，该如何处
    理。
        latest：默认，偏移量无效时，消费者从最新的记录开始读取，以消费者启动时生成的记录为准
        earliest：偏移量无效时消费者从起始位置读取分区的记录

    enable.auto.commit：
        是否自动提交偏移量，默认是true。可以设置成false避免出现重复数据和数据丢失。如果设为true，可以通过
    auto.commit.interval.ms来控制提交的频率

    partition.assignment,strategy：
        默认使用的是Range策略，也就是org.apache.kafka.clients.consumer.RangeAssignor类。也可以使用自定义策略，这就
    需要将该配置改成全类名
        分区分配策略：
            Range：该策略会把主题的若干个连续的分区分配给消费者。也就是说如果有3个分区，2个消费者，那么第一个消费者会
        先分到前两个分区，第二个消费者再分配到一个。而此时如果这两个消费者同时消费2个主题，且这两个主题都有3个分区，
        那么按照相同的规则第一个消费者将分到4个分区，第二个消费者将分配到两个分区。所以Range每次分配都是以主题为单位
            RoundRobin：该策略会把主题的所有分区逐个分配给消费者。可以理解为遍历所有的消费者，然后从分区集合里一个个
        拿出来分配，如果消费者遍历完了还有分区，就进行下一轮，这能保证每个消费者的分区最多相差一个

    client.id：
        可以是任意字符串，broker用它来标识从客户端发送过来的消息，通常用在日志、度量指标或者配额里

    max.poll.records：
        该属性用于控制单次调用call()方法能返回记录数量，可以控制在轮询里需要处理的数据量

    receive.buffer.bytes：
        socket在读数据时用到的TCP缓冲区大小，如果是-1则使用操作系统的默认值，如果消费者和broker处于不同的数据中心，
    就可以适当的增大这个值，因为跨数据中心的网络一般延迟高，缓冲区大一点可以增加每次传输的数据量

    send.buffer.bytes：
        功能同receive.buffer.bytes，不过这个是发送数据时的TCP缓冲区大小

消费者方法：
    kafkaConsumer.subscribe(List topicList)：
        订阅指定的topic列表，且topic可以写正则表达式，比如：test.*

    poll：
        向kafka轮询消息，可指定超时时间，一般情况使用poll()的逻辑如下：
        1、消费者会在一个无限循环里，通过持续轮询向Kafka请求数据
        2、消费者会通过poll()来发送心跳与请求数据。并且可以指定poll的超时时间，在指定的时间内会一直等待broker返回数据
        3、poll()会返回一个记录列表。每条记录都包含了记录所属主题的信息、记录所在分区的信息、记录在分区里的偏移量、记
    录的键值对。我们一般会遍历这个列表，逐条处理这些记录

    消息轮询是消费者API的核心。一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳、获
取数据。在第一次调用新消费者的pool()方法时，它会负责查找GroupCoordinator，然后加入群组，接受分配的分区。如果发生
了再均衡，整个过程也是在轮询期间进行的。心跳也是在轮询里发出去的。所以轮询期间的工作应该尽快完成


提交和偏移量：

    



















