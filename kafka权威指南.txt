发布与订阅消息系统：
    数据的发送者不会直接把消息发送给接收者，而是对消息进行分类，然后接受者订阅特定类型的消息，这是发布与订阅消息系
统的特点。发布与订阅系统一般会有一个broker，也是发布消息的中间点，broker主要用来分发消息，也可以提供一些额外的功
能，比如延迟发送

kafka的消息简介：
    kafka的消息有一个可选的元数据，也就是键。键与消息一样也是一个字节数组，当需要消息以一种可控的方式写入不同分区时
，就会用到键，最简单的就是用键生成HashCode，然后对分区数进行取模，为消息分区，这样保证了相同键的消息总是被写到相
同的分区上

kafka的批次简介：
    为了提高效率，消息被分批次写入kafka，批次就是一组消息，这些消息属于同一个主题和同一个分区，如果每个消息都单独穿
行于网络，会导致大量网络开销。
    把消息分成批次传输可以减少网络开销，不过会造成延迟，所以需要在延迟与吞吐量之间做出权衡。批次越大，单位时间内处
理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据传输与存储能力，但要做更多计算处理


消息模式简介：
    消息不过是晦涩难懂的字节数组，消息模式可以以特定的结构来定义消息内容，比如JSON和XML。其实模式指的就是序列号方
式。模式与消息是分开的，当模式发生变化时，不需要重新生成代码

主题和分区简介：
    kafka的消息通过主题进行分类。主题就好比数据库的表，或文件系统的文件夹。主题可以被氛围若干个分区，一个分区就是一
个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取
    由于一个主题包含多个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序
    kafka通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说一个主题可以横跨多个服务器，以此来提
供比单个服务器更强大的性能
    我们通常会用流这个词来描述kafka这类系统的数据

生产者和消费者简介：
    生产者创建消息，一般情况下，一个消息会被发布到一个特定的主题上。
    生产者在默认情况下会把消息均衡地分布到主题的所有分区上，而不关心消息会被写到哪个分区。不过如果指定了分区键和分
区器，生产会把消息写到指定的分区，分区器会为键生成一个散列值，并将其映射到指定的分区上。这样保证了同一个键会被写到
同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区
    消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。
    消费者通过检查消息的偏移量来区分已经读取过的消息，偏移量是一个不断递增的整数值，在一个分区里，每个消息的偏移量
都是唯一的。消费者把每个分区最后读取的消息偏移量保存在zookeeper或kafka上，保证消费者关闭或重启后，读取状态不丢失
    消费者是消费者组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用，
但是一个消费者可以同时消费多个分区，因为这样才能保证消息消费的顺序
    如果一个消费者失效，群组里的其它消费者可以接管失效消费者的工作，也就是去接手消费它的分区

broker和集群简介：
    一个独立的kafka服务器被称为broker。broker接受来自生产者的消息，为消息设置偏移量，并将消息保存到磁盘。broker为
消费者提供服务，对读取分区的请求做出响应，返回磁盘上已提交的消息。根据特定的硬件与性能特征，单个broker可以轻松处理
数千个分区以及每秒百万级的消息量
    broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色，这个角色是自动选举出来的。控制器负责
管理工作，包括将分区分配给broker和监控broker。
    在集群中，一个分区属于一个broker，该broker称为该分区的首领。一个分区可以分配给多个broker，此时会发生分区复制，
这种复制机制为分区提供了消息冗余，如果某个分区的首领broker失效了，其它broker可以接管该分区的领导权，不过生产者和
消费者都要连接到新的首领broker

保留消息：
    kafka broker的消息保留策略是：要么保留一段时间(比如7天)，要么在保留消息的字节数达到一定大小(比如1G)。当消息达到
上限时，旧消息就会过期并被删除
    每个主题都可以配置自己的保留策略。也可以通过配置将主题当做紧凑型日志，紧凑型日志只会为每个不同的键保留最后一条
变更的消息

多集群：
    随着kafka部署数量的增加，基于以下原因，最好使用多个集群：
        1、数据类型分离
        2、安全需求隔离
        3、多数据中心(灾难恢复)
    多个数据中心之间，如果要保证数据一致，就需要在它们之间复制消息。不过kafka的消息复制机制只能在单个集群里进行，不
能在多个集群之间进行
    不过kafka提供了一个叫做MirrorMaker的工具，它可以实现集群间的消息复制。MirrorMaker的核心组件包含了一个生产者和
一个消费者，两者通过一个队列连接。消费者从一个集群中读取消息，生产者再把消息发送到另一个集群上。
    比如，多个Kafka集群都先用MirrorMaker的消费者消费消息，然后用生产者发送到另一个统一聚合集群里，然后将这个聚合集
群的消息再用相同的方式复制到另一个数据中心即可

kafka中的zookeeper：
    在kafka中，zookeeper的作用主要是保存broker、主题、消费者的元数据与消费者的分区偏移量

    zookeeper集群：
        关于zookeeper的作用与选举的相关知识，可以看zookeeper.txt，这里介绍zookeeper集群的配置：
        zookeeper群组不建议超过7个，因为zookeeper使用了一致性协议，节点太多会降低性能，如果希望在线更新zookeeper的
    配置，可以修改后依次重启每个节点，既能高可用又能改到配置
        每个zookeeper服务器还要在数据目录中创建一个myid文件，用于指明自己的服务器id，文件内容如下：
            tickTime=2000：指定基础的时间单位，与其它时间配置配合使用
            dataDir=/var/lib/zookeeper：zookeeper的目录
            clientPort=2181：客户端端口，专门给客户端api使用的端口
            initLimit=20：从节点与主节点建立初始化连接的时间上限，20的意思是(tickTime的20倍)毫秒
            syncLimit=5：允许从节点与主节点不同步状态的时间上限，5的意思是(tickTime的5倍)毫秒
            server.1=zoo1.boc.com:2888:3888
            server.2=zoo2.boc.com:2888:3888
            以上两行配置：server.是固定值；1代表服务器id，必须是整数，不能重复，此id要与zookeeper的配置文件id一直，其它
        没要求；zoo1.boc.com是服务器名或ip；2888是用于节点之间通信的端口；3888是用于leader选举通信的端口


broker：

    注意！很多配置既可以用在broker级别，用于控制所有主题的行为，也可以应用在主题级别，用于控制个别主题的行为。主题
级别的配置在主题内将会覆盖broker级别的配置

    broker.id：
        每个broker都需要有一个唯一标识，默认值是0，可以设置成任何整数，这个值在集群中必须唯一

    port：
        kafka默认端口是9092，如有需要可以自行修改

    zookeeper.connect：
        zookeeper的连接地址，默认是localhost:2181，可以指定多个，用分号分隔，这样如果某个zookeeper挂了可以连其他的
        比如localhost:2181/kafka;localhost:2182/kafka，后面的kafka是broker在zookeeper中的根路径，默认为/

    log.dirs：
        保存消息的路径，多个用逗号分隔，如果指定多个，broker会保证相同分区的日志片段保存到相同的路径，新的分区会根
    据最小分区原则选择路径，也就是哪个路径的分区最少就选哪个

    num.recovery.thread.pre.data.dir：
        kafka启动和停止时的线程数
        对于一下3种情况，kafka会使用线程池来处理日志：
            1、服务器启动时，用于打开每个分区的日志片段
            2、服务器奔溃后重启，用于检查和截短每个分区的日志片段
            3、服务器关闭时，用于关闭日志片段
        默认情况下，每个日志目录只是用一个线程，线程池只是在服务器启动和关闭时用来加速用的
        如果这个值设置为8，代表每个目录需要8个线程，此时如果log.dirs又有3个目录，那么一共需要8*3=24个线程

    auto.create.topics.enable：
        kafka是否自动创建topic，以下几种情况会自动创建topic：
            1、生产者往主题写入消息
            2、消费者从主题读消息
            3、客户端向主题发送元数据相关请求

     replica.lag.time.max.ms：
        指定了副本复制消息时的最大延迟时间，如果超过这个时间，那么首领分区会认为这个broker的副本复制失败了。消费者
    只能看到已被复制成功的数据

    log.cleaner.enabled：
        启用日志片段清理功能，详情看下面清理部分的介绍

    cleanup.policy：
        kafka的日志清理策略，可选值如下：
            delete：根据日志片段的大小与片段不活跃时间来删除
            compact：只保留主题中每个key的最后一个value，topic_consumer_offsets默认为此策略，此策略下对空间与时间
        无限制

    broker.rack：
        机架名称，kafka会在为broker分配分区副本时，尽量将一个分区的不同副本分布在不同的机架上，以防止机架故障导致
    某个分区的多个副本不可用

主题的配置：
    num.partittons：
        自动创建主题时的分区数量

    log.retention.ms：
        数据可以被保留的时间，单位为毫秒
    log.retentoin.minutes：
         数据可以被保留的时间，单位为分钟
    log.retentoin.hours：
         数据可以被保留的时间，单位为小时，默认值为168，也就是一周
    以上几个数据保留时间配置，当多个同时存在时，以最小值的为准
    注意，以上几个配置都是以日志片段的最后更新时间为准，一个日志片段就是一个文件，也就是说，如果日志片段10天才写满，
那么过期时间将从第十天开始算

    log.retenion.bytes：
        每个分区的数据最多可以被保留的字节数，单位为字节，如果和log.retention.ms同时指定，则满足任意一个就会删除消息

    log.segment.bytes：
        日志片段的大小，单位为字节，默认为1G，到时间后日志片段将被关闭。如果太大就会影响到数据过期时间，根据时间戳获
    取偏移量等操作，因为它们都是基于日志片段的信息来计算的
        比如根据时间戳获取偏移量，kafka会找到分区里最后修改时间大于指定时间戳的日志片段(已被关闭的)，然后返回该日志片
    段的开头偏移量，日志片段越小准确度越高

    log.segment.ms：
        日志片段被关闭的时间，单位为毫秒，默认不开启。与log.segment.bytes之间任意一个满足条件就会关闭日志片段。日志片
    段的过期时间是从broker启动之后开始计算的

    message.max.bytes：
        单个消息的大小限制，默认值是1000000，也就是1MB。如果超过broker会返回报错信息，该参数计算的是消息被压缩后的
    大小


kafk的硬件关注点：
    磁盘的吞吐量(影响生产者，磁盘写入越快，生产者提交就越快)、磁盘容量(影响需要保留的数量量)、内存(影响消费者，消息会
放在系统页面缓存，或者缓存消息片段)、网络(虽然也重要，但与机器本身无关)、CPU(压缩和解压，kafka对这方面要求不高)


broker集群的基本配置：
    zookeeper.connect：
        zookeeper的群组和路径
        broker.id：每个broker中的id再集群里必须唯一

生产者：

    消息生产概览：
        1、创建一个ProducerRecord对象，其中包含了主题、消息内容、键、分区
        2、生产者把键和值对象序列化成字节数组
        3、数据传给分区器，如果ProducerRecord指定了分区，分区器就不会做任何事，否则分区器会根据ProducerRecord的键
    来指定一个分区
        4、这条记录被添加到一个记录批次里，这个批次里的所有消息都是同样的主题和分区
        5、有一个独立的线程负责把这些记录批次发送到对应的beoker上
        6、如果消息成功写入Kafka，就返回一个RecordMetaData对象，它包含了主题和分区的信息，以及消息在分区中的偏移量
        7、如果消息写入失败，就会返回一个错误，生产者收到错误后会尝试重复发送消息，如果多次后依然失败，就返回错误消息

    生产者对象属性：
        bootstrap.servers：
            必填，指定broker地址清单，地址格式为host:port，多个地址用逗号分割。清单里不需要包含所有broker地址，生产者
        会从给定的broker里找到其它broker的信息。不过建议多提供几个，以便其中某些宕机，生产者依然能从剩余的broker地址
        里连接到集群上

        key.serializer：
            必填，key的序列化类，必须实现org.apache.kafka.common.serialization.Serializer接口，生产者会使用这个类把键序
        列化成字节数组。kafka默认提供了ByteArraySerializer、Stringserializer、IntergerSerializer

        value.serializer：
            必填，与key.serializer一样，描述请参考key.serializer

        acks：
            指定必须有多少个分区副本收到消息，生产者才认为消息写入是成功的
            acsk=0：则生产者不等待服务器的响应，如果丢失了消息生产者也无从得知，当然，这样吞吐量也是最高的
            acks=1：只要集群里目标分区的首领节点收到消息，生产者就会收到服务器的成功响应。否则就会收到错误响应，如果收
        到了错误响应，生产者会重发消息。
            acks=all：当所有参与复制的分区节点都收到消息时，生产者才会收到服务器的成功响应。这种模式是最安全的，不过延
        迟也比较高

        buffer.memory：
            设置生产者内存缓冲区的大小，用来缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度
        ，导致生产者缓冲区空间不足，这时候send方法会被阻塞或者抛出异常

        max.block.ms：
            与buffer.memory有关，它用来表示当生产者缓冲区不足的时候，再抛出异常之前可以阻塞的时间，当超过阻塞时间依然
        空间不足才会抛出异常

        compression.type：
            消息压缩方式，默认情况下消息发送时不会被压缩。该参数可以设置为：snappy、gzip、lz4。指定消息在发送到broker
        之前使用哪种压缩算法。snappy比较均衡，CPU占用不高，压缩比也还可以，gzip的CPU占用较高，但压缩比也更高

        retries：
            重发消息的次数，服务器返回的错误可能是临时性的，必须分区在选举首领。这种情况下重发就可能会成功

        retry.backoff.ms：
            重发消息的间隔

        batch.size：
            当多个消息需要发送到相同的分区时，生产者会把他们放到同一个批次里。该参数指定了一个批次的内存大小，按字节计
        算。当批次被填满时，批次里所以消息都会被发送出去

        linger.ms：
            批次发送前等待的毫秒数，如果时间到了，批次还没满，生产者也会吧消息发出去，哪怕只有一个消息

        client.id：
            服务器用来识别消息的来源，可以用在日志和配额指标里

        max.in.flight.requests.pre.connection：
            指定了生产者在收到服务器响应之前可以发送多少个消息。值越高就会占用越多内存。值为1就能保证消息的顺序，哪怕
        发生了重试。如果大于1，可能同时发两条，第一条消息失败，第二条成功，第一条再重试，顺序就颠倒了

        timeout.ms：
            指定等待同步副本返回消息的确认时间，如果指定时间内没收到同步副本的确认，broker就会返回错误。broker会不会等
        待同步副本返回消息取决于acks的配置

        metadata.fetch.timeout.ms：
            生产者获取元数据时(比如分区受理是谁)，等待服务器返回响应的时间，如果超过指定时间则抛异常

        request.timeout.ms：
            生产者在发送数据时等待服务器返回的响应时间，如果超过指定时间则抛异常

        max.block.ms：
            调用send方法或者用partitionsFor方法获取元数据时生产者的阻塞时间。当生产者发送缓冲区已满或者没有可用元数据时
        ，这些方法就会阻塞。如果阻塞时间达到指定时间生产者就会抛出异常

        max.request.size：
            控制生产者发送的请求大小。可以指定单个消息的最大值，也可以用来指定单个请求里所有消息的总大小，比如1MB。
        broker那边也可以配置message.max.bytes对消息进行限制，两边最好可以匹配，避免生产者的消息被拒绝

        receive.buffer,bytes：
            TCP接受数据包的缓冲区大小，如果为-1则使用操作系统的默认值

        send.buffer.bytes：
            TCP发送数据包的缓冲区大小，如果为-1则使用操作系统的默认值

    发消息方法：
        发送并忘记：
            producer.send(record)，发送后就不管了
        同步发送：
            producer.send(record)会返回一个Future对象，只要马上就调future.get()进行等待，就是同步了
        异步发送：
            producer.send(record, callback)，kafka在收到broker的响应后会异步回调callback的代码，这个回调可能会包含异常
        信息，异步发送很适合在不需要kafka响应时使用，这样只发消息不等待响应，比发消息后等待响应所需的时间少很多

    生产者的异常：
        可重试错误：
            这类错误可通过重发消息来解决，比如：连接错误、no leader错误，kafka生产者可以被配置成自动重试，如果多次重试
        都无法解决问题，就会抛出重试异常

        不可重试错误：
            这类消息无法通过重试解决，比如消息太大异常，这类错误kafka不会进行重试，而是直接抛异常

    生产者在不使用时记得flush或者close，否则由于消息是分批发送的，如果刚发完生产者还没发送进程就结束了，就会导致消息
丢失


序列化器：

    虽然有很多不同类型的序列化器，不过基本都是用JSON转字符串后，再用StringSerializer

    书里还提供了Avro序列化框架的示例，不过还要另外搞一个服务器来提供不同的类型版本，比较麻烦


分区：

    默认分区器对key使用散列算法进行分区，如果没有key就随机分区

    自定义分区器：
        实现Partitioner接口然后在partition方法返回想指定的分区，configure传入生产者的配置，close在生产者关闭时调用


消费者和消费者组：

    Kafka消费者属于消费者组，一个群组里的消费者订阅的是同一个主题，其中的每一个消费者接受主题的一部分分区的消息。如
果一个群组里有多个消费者，那么主题的分区将会被组里的消费者平分，每个分区在一个消费者组里最多同时被一个消费者进行消
费。也就是如果消费者组的消费者数量比分区多，那么有部分消费者就会被闲置

    每个消费者组都能读到主题的全部消息

    分区再均衡：
        一个新的消费者加入群组时，它读取的是原本其它消费者读取的消息。一个消费者被关闭或者发生崩溃时，它读取的分区将
    由其它消费者来读取。
        分区的消费权从一个消费者转移到另一个消费者，这种行为被称为再均衡。再均衡为消费者群组带来了高可用性和伸缩性，
    不过在再均衡期间，消费者无法读取消息，会造成群组一小段时间不可用。另外，当分区被重新分配给另一个消费者时，消费
    者当前的读取状态会丢失，可能还要去刷新缓存来恢复状态
        消费者通过被指派为群组协调器的broker发送心跳来维持他们对分区的所有权与它们跟群组的从属关系。只要消费者以正常
    的时间间隔发送心跳，就被认为是活跃的。消费者会在轮询消息或提交偏移量时发送心跳。当消费者停止发送心跳的时间足够
    长，群组协调器就会认为它已死亡，此时会触发一次再均衡

    分配分区过程：
        1、消费者向群组协调器发送一个JoinGroup请求，第一个加入的消费者将成为群主
        2、群主从协调器那里获取群组的成员列表，群组列表包含最近发送过心跳的消费者。并负责给每一个消费者分配分区。分区
    分配使用ConsumerPartitionAssignor接口的实现类进行，旧版是PartitionAssignor（已废弃）
        3、群主分配完毕后会把分配情况发给群组协调器，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的消费
    信息，只有群主知道群组里所有消费者的分配信息，这个行为会在每次在均衡时重复发生

消费者参数：

    bootstrap.servers：
        制定多个broker地址，语义和生产者的同名属性相同

    key.deserializer：
        key的反序列化类，实现于Deserializer接口

    value.deserializer：
        value的反序列化类，实现于Deserializer接口

    group.id：
        指定消费者组

    fetch.min.bytes：
        指定消费者从服务器获取记录的最小字节数。broker会在收到消费者的数据请求时，如果可用的数据量小于fetch.min.bytes
    时，会等到有足够的数据才返回给消费者。这可以降低消费者和broker的负载，如果数据不多，但消费者CPU使用率很高，那
    就可以把这个参数设置的比默认值大

    fetch.max.wait.ms：
        指定broker的等待时间，默认是500ms。如果kafka流入的数据满足不了fetch.min.bytes，那么最多导致fetch.max.wait.ms
    的延迟。
        可以将fetch.min.bytes指定的高一些，比如1MB，fetch.max.wait.ms指定的低一些，比如100ms，将CPU使用率和消息延
    迟控制在一个可接受的范围。这样数据要么满足1MB，要么等到100ms，满足任一个都会返回

    max.partition.fetch.bytes：
        指定了服务器从每个分区里返回给消费者的最大字节数。默认值是1MB，kafkaConsumer.poll()方法从每个分区里返回的记
    录最多不超过max.partition.fetch.bytes指定的字节。
        如果一个主题有20个分区，5个消费者，那么每个消费者至少要有4MB的内存来接收记录，而且还要考虑其它消费者崩溃发
    生再均衡，导致剩下的消费者需要处理更多分区
        max.partition.fetch.bytes一定要比max.message.size大，否则如果单条消息就超过了max.partition,fetch.bytes，那么这
    条消息就可能无法成功读取，导致消费者一直挂起重试
        还要考虑如果max.partition.fetch.bytes太大会导致消息过多，消费者无法及时调用下次poll()来避免会话过期，如果出现这
    种情况可以改小改值，或者延长会话时间

    session.timeout.ms：
        指定了消费者在被认为死亡前可以与服务器断开连接的时间，也就是最长心跳间隔，默认是3s。
        如果消费者没有在session.time.out指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，将它
    的分区分配给其它消费者。
        session.timeout.ms一般与hearbeat.interval.ms配合使用
        session.timeout.ms设置的比较小可以更快地检测和恢复崩溃的节点。不过长时间的轮询和GC可能会导致预料之外的再均衡
    ，所以大一些可以避免意外情况。根据具体场景去选择

    hearbeat.interval.ms：
        指定poll()方法向协调器发送心跳的频率，一般是session.timeout.ms的三分之一，必须小于session.timeout.ms

    auto.offset.reset：
        指定消费者在读取一个没有偏移量的分区，或者偏移量无效(消费者长时间失效，偏移量的记录已被删除)的情况下，该如何处
    理。
        latest：默认，偏移量无效时，消费者从最新的记录开始读取，以消费者启动时生成的记录为准
        earliest：偏移量无效时消费者从起始位置读取分区的记录

    enable.auto.commit：
        是否自动提交偏移量，默认是true。可以设置成false避免出现重复数据和数据丢失。如果设为true，可以通过
    auto.commit.interval.ms来控制提交的频率

    partition.assignment,strategy：
        默认使用的是Range策略，也就是org.apache.kafka.clients.consumer.RangeAssignor类。也可以使用自定义策略，这就
    需要将该配置改成全类名
        分区分配策略：
            Range：该策略会把主题的若干个连续的分区分配给消费者。也就是说如果有3个分区，2个消费者，那么第一个消费者会
        先分到前两个分区，第二个消费者再分配到一个。而此时如果这两个消费者同时消费2个主题，且这两个主题都有3个分区，
        那么按照相同的规则第一个消费者将分到4个分区，第二个消费者将分配到两个分区。所以Range每次分配都是以主题为单位
            RoundRobin：该策略会把主题的所有分区逐个分配给消费者。可以理解为遍历所有的消费者，然后从分区集合里一个个
        拿出来分配，如果消费者遍历完了还有分区，就进行下一轮，这能保证每个消费者的分区最多相差一个

    client.id：
        可以是任意字符串，broker用它来标识从客户端发送过来的消息，通常用在日志、度量指标或者配额里

    max.poll.records：
        该属性用于控制单次调用call()方法能返回记录数量，可以控制在轮询里需要处理的数据量

    receive.buffer.bytes：
        socket在读数据时用到的TCP缓冲区大小，如果是-1则使用操作系统的默认值，如果消费者和broker处于不同的数据中心，
    就可以适当的增大这个值，因为跨数据中心的网络一般延迟高，缓冲区大一点可以增加每次传输的数据量

    send.buffer.bytes：
        功能同receive.buffer.bytes，不过这个是发送数据时的TCP缓冲区大小

消费者方法：
    kafkaConsumer.subscribe(List topicList)：
        订阅指定的topic列表，且topic可以写正则表达式，比如：test.*

    poll：
        向kafka轮询消息，可指定超时时间，一般情况使用poll()的逻辑如下：
        1、消费者会在一个无限循环里，通过持续轮询向Kafka请求数据
        2、消费者会通过poll()来发送心跳与请求数据。并且可以指定poll的超时时间，在指定的时间内会一直等待broker返回数据
        3、poll()会返回一个记录列表。每条记录都包含了记录所属主题的信息、记录所在分区的信息、记录在分区里的偏移量、记
    录的键值对。我们一般会遍历这个列表，逐条处理这些记录

    消息轮询是消费者API的核心。一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳、获
取数据。在第一次调用新消费者的pool()方法时，它会负责查找GroupCoordinator，然后加入群组，接受分配的分区。如果发生
了再均衡，整个过程也是在轮询期间进行的。心跳也是在轮询里发出去的。所以轮询期间的工作应该尽快完成


提交和偏移量：

    kafka不会像其它JMS队列那样需要得到消费者的确认，这是kafka的独特之处，消费者可以使用kafka来追踪消息在分区里
的位置(偏移量)。
    我们把更新分区当前偏移量的操作叫做提交
    消费者往一个叫做_consumer_offset的特殊主题发送消息，消息里包含每个分区的偏移量。如果消费者一直运行，那么偏移
量没什么用处。但是如果消费者崩溃，或者有新的消费者加入消费组，就会触发再均衡。完成再均衡后，每个消费者都可能会
分到新的分区，为了能继续之前的工作，消费者需要读取每个分区的最后一次提交的偏移量，再从偏移量指定的地方继续处理
    当提交的偏移量小于客户端实际处理的最后一个消息的偏移量，那么两个偏移量之间的消息就会被重复消费。如果提交的偏
移量大于当前处理的偏移量，那么当前偏移量与提交偏移量之间的消息就会丢失

    消费者提交偏移量的方式：
        1、自动提交：
            消费者属性中enable.auto.commit如果设置为true，那么每过5s，消费者会自动把poll()方法接收的最大偏移量提交上
        去，提交时间间隔可以用auto.commit.interval.ms控制，默认值是5s。
            不过自动提交有风险，比如还没到5s就发生了再均衡，那么这期间的消息会重复消费。消费者在调用close()方法之前也
        会进行自动提交

        2、提交当前偏移量
            把auto.commit.offset设为false，让应用程序自己决定何时提交偏移量。

            commitSync()：同步提交，这个API会提交由poll()方法返回的最新偏移量，提交失败就抛出异常，成功就马上返回，
        在遇到不可恢复的错误之前，commitSync()会一直重试，直至成功

            commitAsync()：异步提交，提交最后一个偏移量，然后马上返回。commitAsync()不会进行任何重试，因为在它收到
        服务器响应的时候，可能有一个更大的偏移量已经提交成功了。
            不过commitAsync()在broker做出响应时支持回调，异步提交可以在本地记录一个提交序列号，如果没有更新的序列号
        说明没有更新的提交。在broker响应错误时就可以通过序列号去决定是否再次提交。
            这样就能做到减少提交阻塞的时间与保证偏移量安全了。因为分区同时只有一个消费者，所以依据变了去记录提交序列
        号还是可靠的

            组合提交：一般情况下，如果偶尔提交失败，不进行重试也不会有太大问题。因为如果是临时问题导致的提交失败，后
        续提交只要有任意一次成功，前面提交失败的偏移量也会包含在内，因此没影响。
            但是如果这次失败是发生在消费者关闭前或者再均衡前的最后一次提交，就要确保能够成功。因为后面可能不再有新的
        提交做兜底了
            那么我们可以在一切正常的时候使用commitAsync()来提交，这样速度更快。当消费者关闭时再调一次commitSync()，
        然后通过再均衡监听器，在发生再均衡之前进行一次commitSync()。这样就能保证偏移量的准确与性能了。
            如果关闭消费者与再均衡监听器时的commitSync()失败了，那么可以在异步提交的回调里拿到偏移量，然后用一个变
        量来保存最新成功的偏移量(每次覆盖前判断是否当前偏移量更大)，然后在同步提交异常时也能拿到一个偏移量，再手工
        对这之间的偏移量做排查。
            因为这些的偏移量可能都是已消费但偏移量没提交的，那么就可以缩小范围进行排查：比如看这些消息是否已被重复消
        费，如果有再对业务数据做相关处理

        注意，以上两种方式都是直接提交当前最新的偏移量，比如poll()返回了100条数据，那么此时调用commitSync()或者
    commitAsync()就会提交刚才返回那批数据的最后一条消息的偏移量。如果想自己控制偏移量，比如当前批次消息只处理了
    部分就要提交偏移量，那么就需要自己去指定要提交哪个主题的哪个分区的指定偏移量

        指定提交的偏移量：
            在commitSync()或者commitAsync()时增加一个Map<TopicPartition, OffsetAndMetadata> offsets参数，其中Key
        里的TopicPartition类型对象里包含了分区与主题属性，且该类根据分区与主题属性重写了equals与hashCode方法，不
        用担心重复提交key重复的问题。而value的OffsetAndMetadata类型里指定了偏移量。所以总结起来主要就三个属性：
        分区、主题、偏移量

关于领域事件的只生产一次，只消费一次：
解决生产一次问题：
    1、生产时事件跟着业务事务保存，所以只要业务事务成功事件肯定会存在
    2、那么如果消息发送失败，可以通过事件表去看生产与消费情况，如果较长时间没被消费就说明可能是消息发送失败，
再通过MQ控制台排查确定后可以重发

解决只消费一次问题：
    1、刚消费就保存消费记录
    2、假如不需要重试，那么可以修改事件消费记录与执行业务用同一个事务，事务提交后ACK。假如前面失败那么等下次消费
，假如ACK失败，那么下次消费时判断事件表里是否已消费，如果已消费则直接ACK


再均衡监听器：
    需要在kafkaConsumer.subscribe()方法的第二个参数传递，该参数需要实现ConsumerRebalanceListener接口，这个接口
有两个方法需要实现：
    public void onPartitionsRevoked(Collection<TopicPartition> partitions)：
        这个方法会在再均衡之前和消费者停止读取消息之后被调用，如果在这里提交偏移量，下一个接管分区的消费者就知道该
    从哪里开始读取了，这个方法结束后将失去对分区的拥有权。
        源码里是在poll的时候调用这个方法的，一般情况下只要调用poll就说明上次的消息已经处理完了，而偏移量一般是每次
    消费时都提交的。因此不会出现偏移量与消息丢失的问题，除非搞异步偏移量，那么这里就要同步提交一下最新偏移量了
    public void onPartitionsAssigned(Collection<TopicPartition> partitions)：
        这个方法会在重新分配分区之后和消费者开始读取消息之前被调用。我们可以从这里知道这次再均衡被分配了哪些分区

从特定偏移量开始处理记录：
    consumer.seek(partition, offset)：指定的分区将从指定偏移量开始消费，seek方法只更新我们正在使用的位置，下次调用
poll()时就能获得seek()指定的消息，如果seek()的位置错误，poll将抛出异常
    书里也提到在同一个事务里把记录和偏移量都写到数据库里，以此来保证记录处理与偏移量提交的原子性
    假设我们有一张表，这张表存储了topic、分区、偏移量，我们每次处理消息时都在同一个事务里更新这条消息所在topic与
分区的偏移量。
    我们就可以在再均衡的onPartitionsRevoked方法里提交当前消费者负责的所有主题与分区在数据库里最新的偏移量；也可
以在onPartitionsAssigned方法里重分配时将消费的主题与分区的偏移量用seek()跳转到数据库里记录的偏移量

优雅退出：
    consumer.wakeup()是消费者唯一一个可以从其它线程里安全调用的方法，这个方法将会在poll时抛出WakeupException
异常，如果当前没在poll，那么下次poll时将抛出。
    我们不需要处理WakeupException，因为它只是一种跳出循环的方式，不过在循环外的finally里调用consumer.close()还是
很有必要的，它会提交任何还未提交的东西，并告知群组协调器自己要离开群组，并立即触发再均衡，而不用等待会话超时
    我们一般在runtime.addShutdownHook里调用consumer.wakeup()

独立消费者：
    直接消费主题或特定分区，不订阅主题、不加入任何消费组、不需要再均衡，为自己分配分区。一个消费者可以订阅主题并
加入消费者组，或者为自己分配分区，这两件事只能同时做一个。用法如下：
    1、consumer.partitionsFor("topic")：获取指定topic的所有分区信息
    2、consumer.assign(partitions)，为消费者指定要消费的topic与分区信息
    3、consumer.poll()，此时消费者去消费只会消费到assign()指定的分区
    4、独立消费者也可以提交偏移量，但是如果下次连接靠什么来区别哪个消费者对应哪个偏移量呢？client.id吗？


集群成员关系：
    Kafka使用Zookeeper来维护集群成员的信息。每个broker都有一个唯一标识符，这个标识符可以在配置文件里指定，也可
以自动生成。
    在broker启动的时候，它通过创建创建临时节点把自己的ID注册到zookeeper，kafka组件在zookeeper的路径是
/brokers/ids。kafka组件订阅了这个节点，当有broker加入集群或者退出集群时，这些组件就可以获得通知
    如果要启动相同ID的broker，后面启动的broker会注册失败，因为zookeeper里已经有一个相同ID的broker了
    当broker停机、出现网络分区或长时间垃圾回收停顿时，broker会从zookeeper上断开连接，此时broker在zookeeper上创
建的临时节点会自动移除。监听broker列表的Kafka组件会被告知该broker已移除
    关闭broker时，它在zookeeper上的节点会消失，不过它的id会继续存在于例如：主题的副本列表里。此时如果一个全新的
broker使用相同的ID启动，它会立即加入集群，并拥有与旧broker相同的分区与主题

控制器：
    控制器其实就是一个broker，只不过它除了一般的broker功能之外，还负责分区首领的选举。集群里第一个启动的broker通
过在zookeeper里创建一个临时节点/controller来让自己成为控制器。其它broker启动时也会尝试创建这个节点，不过它们会
创建失败，创建失败后它们会监听这个节点，一旦监听到这个节点消失它们就会尝试成为新的控制器。这种方式可以确保集群
里一次只有一个控制器存在，并且控制器出现问题时其它broker可以作为新的控制器

    当控制器发现一个broker已经离开集群，并且这个broker上的分区刚好存在首领分区。控制器就会遍历这些分区，然后从这
些分区的副本里确定谁改成为首领，然后向这个分区的所有broker发送请求，改请求包含了谁是分区新首领以及谁是分区跟随
者的信息。随后新首领开始处理来自生产者和消费者的请求，而跟随者从新首领那里复制消息

    当控制器发现一个broker加入集群时，它会使用broker ID来检查新加入的broker是否包含现有分区的副本。如果有，控制
器就把变更通知发给新加入的broker与其它broker，新broker上的副本开始从首领那里复制消息

    总的来说，kafka使用zookeeper临时节点来选举控制器，并监听节点的变更。而控制器则负责分区的首领选举。控制器使用
epoch来避免脑裂(指两个节点同时认为自己是当前的控制器)


复制：
    Kafka的副本有两种类型：
        首领副本：
            每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本

        跟随者副本：
            除了首领副本意外的副本都是跟随者副本。跟随者副本唯一的任务是从首领那里复制消息，保持与首领一致的状态。如
        果首领发生奔溃，其中一个跟随者会被提升为新的首领

    首领的另一个任务是搞清楚哪个跟随者的状态是与自己一致的。跟随者会在有新消息时尝试从首领那里复制消息，以此保持
与首领的状态一致。不过有各种原因会导致同步失败，例如：网络堵塞，broker奔溃
    副本向首领请求消息的时候，总是有序地去请求，前面的请求响应之前它是不会发送下一个请求的。例如跟随者发送偏移量
为4的消息请求，那么首领就认为他已经收到了前面1-3请求的响应。通过查看每个跟随者请求的最新偏移量，首领节点就会知
道每个跟随者复制的进度。如果跟随者在10s内没有请求任何消息，或者虽然有请求，但是请求的不是最新的数据，那么首领就
会认为这个跟随者是不同步的。如果一个副本无法跟首领保持一致，当首领失效时，它就不可能成为新首领，因为它没有包含
全部的消息
    当首领发生失效时，只有同步副本才有可能被选为新的首领，同步副本的条件如下：
        1、与zookeeper之间有一个活跃的会话，在过去6s(可配置)内有向zookeeper发送过心跳
        2、在过去10s(可配置)内从首领那里获取过消息
        3、在过去10s内从首领那里获取过最新的消息，保证跟随者副本必须是几乎0延迟
        如果跟随者副本不满足以上条件则被认为是不同步的。一个不同步的副本通过与zookeeper重建连接，或者从首领那里
    重新消费最新消息后，就可以变成同步的

        如果一个或多个副本在同步与非同步之间快速切换，说明集群内除了问题，通常是Java不恰当的垃圾回收配置导致的。
    不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker和zookeeper之间断开连接，最后变成不同步的，进而发生状态
    切换
        一个滞后但依然同步的副本会导致生产者和消费者变慢，因为消息在变为已提交之前，客户端会等待所有同步副本接
    收消息。反而如果副本不再同步了，它就不会对性能产生任何影响，因为首领副本不再会关心它是否收到消息。但是发生
    宕机时，更多的非同步副本意味着更低的有效复制系数，丢失数据的风险也更大

    replica.lag.time.max.ms指定了副本在复制消息时允许的最大延迟时间

    除了当前首领之外，每个分区都有一个首选首领，首选首领在创建主题时指定。之所以叫首选首领，是因为在创建分区时，
需要在broker之间均衡首领，尽量将首领均匀分布在所有broker上。
    auto.leader.rebalance.enable如果为true，kafka就会检查首选首领是不是当前首领，如果不是，且该副本时同步的，就会
触发首领选举，让首选首领成为当前首领。首选首领成为当前首领就能让broker之间的首领负载得到均衡吗？难道是靠手动切
换首选首领？


处理请求：
    broker的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求。kafka基于TCP提供了一个二进制协议，指
定了请求消息的格式以及broker如何对请求做出响应，包括成功处理请求与处理请求的过程中发送的错误。broker按照请求到
达的顺序来处理它们，这种顺序保证了kafka具有消息队列的特性，同时保证保存的消息也是有序的

    broker会在它监听的每一个端口运行一个Acceptor线程，这个线程会创建连接，并交给Processor线程去处理。Processor也
叫网络线程，它的数量是可配置的。网络线程负责从客户端获取消息，把它们放入请求队列，然后从响应队列获取响应消息，
把它们发送给客户端。而IO线程负责处理请求队列里的请求，有以下几种常见的请求类型：
    生产请求：
        生产者发送的请求，包含客户端要写入broker的消息。
        收到消息的broker会根据请求里的acks值来决定是立即返回还是等待副本写入后才返回。如果acks为all，那么请求会被保
    存在一个叫做‘炼狱’的缓冲区里，直到所有副本都复制了消息才响应客户端
        如果指定了acks=all，那么副本在replica.lag.time.max.ms时间内无法写入成功的，就会给客户端返回失败，就算首领分
    区写入成功了也无法被消费到

    获取请求：
        消费者与跟随者副本从broker读取消息的请求
        客户端向broker的请求可以指定，从哪些主题的哪些分区里消费，并且指定每个分区的消费的起始偏移量。并且能指定
    broker最多可以从一个分区里返回多少数据，这个限制非常重要，因为客户端要为broker返回的数据分配内存，如果没有这
    个限制，broker返回的数据可能会耗尽客户端的内存
        kafka使用零复制技术向客户端发送消息，也就是说kafka把消息直接从文件系统里发送到网络通道，而不需要经过任何中
    间缓冲区，这样能避免字节复制，也不需要管理内存缓存，从而获得更好的性能
        假如某条消息在首领分区写入成功，但是在副本分区里经过replica.lag.time.max.ms时间后仍未成功，那么这条消息是生
    产失败的，因此消费者也无法看到这条消息。因为考虑到broker下线切换首领的时候，如果某些broekr有这个消息，某些
    broker没有，就会出现消息不一致

    元数据请求：
        参数是主题列表，响应是这些主题包含的分区、每个分区的副本、其中哪个是首领副本等信息

    其它请求：
        除了以上三种请求之外，kafka里还有其他请求，这些请求是在kafka内部使用的，与客户端无关，比如：内部的选举请求
    、还有kafka决定不用Zookeeper保存偏移量而是用特定的kafka主题保存偏移量后，又多了几种偏移量相关的请求、还有主
    题创建不再直接向zookeeper里更新，而是通过kafka的请求进行更新，因为不是所有语言都有zookeeper的客户端、还有
    询问broker支持那些版本的请求等等

    Acceptor(TCP握手后将socket交给Processor处理) -> Processor(将请求放进请求队列) -> IO线程(消费请求队列的数据，
进行处理后将结果写入响应队列) -> Processor(从响应队列中消费数据，并返回给客户端)

    生产请求与获取请求都必须发送给分区的首领副本。如果broker收到指定分区的请求，而该分区的首领在其它broker上，那
么会给客户端返回一个非分区首领的错误响应。
    Kafka客户端要自己负责把生产请求和获取请求发送到正确的broker上，客户端通过向任意一个broker发送元数据请求来获
取相关信息，因为所有broker都缓存了这些信息。一般情况下，客户端会把这些信息缓存起来，然后根据缓存的元数据发送获
取请求与生产请求。客户端也会是不是发送元数据请求来刷新这些缓存信息，刷新时间通过metadata.max.age.ms来指定
    当客户端收到非分区首领错误时，客户端会先刷新元数据，然后再尝试重发请求，因为这个错误代表客户端使用了过期的元
数据来发送请求

    新的kafka broker能处理旧的请求，但是旧的broker不一定能处理新的请求，因此如果要升级kafka应该先升级broker再升
级客户端


物理存储：

    分区分配基本原则：
        1、相同的分区副本不能出现在同一个broker上
        2、kafka在分区分配时，会在当前运行的所有broker里尽量进行均匀分配
        3、如果broker指定了机架信息，那么kafka会尽量将分区分配给不同机架的broker

    分配流程：
        1、随机选择一个broker，这个broker将是第一个要分配分区的首领分区
        2、选择下一个broker，如果有机架则选择下一个机架里的broker，这个broker是第一个分区的跟随者分区
        3、总的来说就是从分区首领开始，依次分配跟随者副本
        4、目录选择，会在用户指定的log.dirs目录里选择已有分区数量最小的目录，此时不考虑磁盘可用空间和工作负载的问题

    文件管理：
        kafka不会一直保留数据，也不会等所有消费者都读取消息后才删除消息。kafka会根据每个主题的数据保留时间或保留大
    小来决定是否删除数据。
        因为在一个大文件里查找和删除消息是很费时的，也很容易出错，所以kafka把分区分成若干个片段。默认情况下，每个
    片段包含1G或者1周的数据，以较小那个为准。如果片段到达上限，就关闭当前文件，并打开一个新文件
        正在写入数据的片段叫做活跃片段。活跃片段永远不会被删除，如果仅要保留一天的数据，但是活跃片段要5天才关闭，
    那么该片段就会被保留五天，前提是片段大小没到上限，因为在片段被关闭之前数据无法被删除

    文件格式：
        kafka的消息和偏移量保存在文件里。保存在磁盘上的数据格式与生产或消费的消息格式是一样的。因为相同的消息格式
    kafka才能用零复制技术技术给消费者发送消息，同时避免对生产者已压缩的消息进行解压和再压缩
        消息里包含了：键、值、偏移量，消息大小、校验和、消息格式版本号、压缩算法、时间戳。其中时间戳可以是生产消息
    的时间或者消息到达broker的时间，这个是可配置的
        如果生产者发送的是压缩过的消息，那么同一个批次的消息会被压缩到一起，被当做‘包装消息’进行发送。同一个批次
    会被压缩成一条消息，消费者解压这个消息后就能看到这个批次的所有消息，它们跟其它普通的消息格式完全一样
        如果在生产端使用了压缩功能(极力推荐)，那么同一批次数据越多，网络传输和磁盘存储方面就会获得更好的性能
        kafka消息里保留了压缩算法的信息，因此消费者可以根据这个信息来进行解压，kafka附带的DumpLogSegment工具也
    可以查看到片段的内容，如果它加了--deep-iteration参数，就可以显示压缩包里的消息，它将通过消息指定的压缩算法进
    行解压

    索引：
        消费者可以从kafka任意偏移量位置开始读取消息，为了帮助broker更快定位到指定偏移量，kafka为每个分区维护了一
    个索引，索引记录了偏移量在哪个片段文件，还有在片段文件里的哪个位置
        索引也被分成片段，所以在删除消息时，可以删除相应的索引。kafka不维护索引的校验和，如果索引出现损坏，kafka会
    通过重新读取消息并记录偏移量与位置来重新生成索引。如果有必要，管理员可以删除索引，这样做是安全的，因为kafka
    会自动重新生成这些索引

    清理：
        一般情况下，kafka会根据设置的时间保留数据，把超过时效的旧数据删掉。不过有一些场景，比如使用kafka保存客户的
    收货地址，那么我们总是只需要最新的地址，之前的旧地址已经意义不大了；还有比如应用状态，我们一般只关心它当前的状
    态，因此应用恢复时，它从kafka读取消息来恢复状态，这种情况下，应用只它关心奔溃前最后的状态，而不关心前面的状态

        因此kafka可以通过改变主题的保留策略来满足这些场景：超过保留时间的数据会被删除、每个键的旧值会被被删除。清
    除键的旧值时，只有包含了键值对的消息才能清除，如果键为Null，kafka就无法确定它是否有重复，清除就会失败

    清理(压缩)的原理：
        当broker配置为cleanup.policy=compact时生效
        每个日志片段都可以分为两个部分：
            干净的部分：
                这部分的消息之前被清理过，每个键只有一个对应的值，这个值是上次清理时保留下来的
            污浊的部分：
                这些消息是在上一次清理之后写入的，无法确认这部分消息与旧消息里是否有重复键
        干净部分的日志片段偏移量可能会有缺失，因为中间可能有一些消息被清除了。而污浊部分的日志片段偏移量总是连续的

        如果kafka启动时通过log.cleaner.enabled启用了清理功能，那么每个broker会启动一个清理管理线程与多个清理线程，
    它们负责执行清理任务。这些线程会选择污浊率较高的分区进行清理，污浊率就是指分区里污浊部分与干净部分的比例。

        为了清理分区，清理线程会读取分区的污浊部分，因为这部分是最新的数据，并用它们在内存里创建一个map。map的键就
    是消息键的散列值，值是偏移量
        键的散列值是16B，也就是128位，值是8B，也就是64位，如果要清理1G的日志片段，假设每个消息大小为1K，那么这个片
    段就包含一百万个消息，而这一百万个消息放到map里只需要24M的就可以清理这个片段，因为相同键的元素只会存在一个

        管理员在配置kafka时可以对map使用的总内存大小进行配置。如果为map分配了1G内存，并使用5个线程，由于每个线程都
    有自己的map，因此每个线程可以用200M来创建自己的map。kafka不要求这个map能放下整个分区的污浊部分，但要求至少能放
    下其中某个完整片段的污浊部分。如果不符合，kafka就会报错，管理员要么分配更多内存，要么减少清理的线程数
        如果只有少部分片段可以符合map分配的内存，kafka将从这些片段里最旧的片段开始清理，清理完成之后再清理剩余部分

        清理线程创建好map之后，此时已经把污浊部分的信息收集完毕放在map中了，这里是每次清理片段呢还是清理整个分区呢
    ？清理后是整个分区的key都唯一了呢还是仅仅片段里key唯一？
        首先将这些map对应的消息复制到复制片段里面，然后清理线程从干净的片段出读取消息，从最旧的消息开始，随后把它
    们与map里的内容进行比较，如果消息的键存在于map中，就代表该键已经有了更新的值，因为map里都是从污浊的片段里读出
    来的，它们都是最新的消息，此时消息会被忽略。如果消息的键不在map中，那说明没有更新的值，消息会被复制到替换片段
    上，然后读取下个消息，干净消息不需要放进map，因为干净片段的key都是清理过唯一的，没有重复的可能。
        就这样，当一个片段中所有消息都复制完后，kafka就将替换片段与原始片段进行交换，然后开始清理下一个片段，完成
    整个清理过程后，分区里每个键都只会保留一个最新的值。

        清理完后的数据每个键只会保留最近的一个消息，那么怎么删除某个键的所有消息呢？
        此时客户端必须发送一个包含该键且值为null的消息。清理线程发现该消息时，会先进行常规清理，清理后只会保留值为
    null的消息。该消息被称为‘墓碑消息’，这个消息会被保留一点时间，具体保留时间根据配置决定。在墓碑消息保留期间
    ，当消费者看到这个消息时，会发现它的值是null，消费者就应该知道这个值应该做相关的删除处理。保留时间过后，清理
    线程将会移除这个墓碑消息，这个键也将从kafka分区里小时。
        删除消息最重要的是要让消费者看到‘墓碑消息’，因为如果墓碑消息没被消费者看到就被清理线程清理了，消费者就不
    知道该消息已经被从kafka里删除了，就也不会去执行相关处理了
        需要注意的是墓碑消息只有在清理策略为：compact时才会有效，因为delete策略会将整个日志片段删除，而不会管里面
    的内容

    主题清理的时机：
        1、与delete策略一样，compact策略也不会对当前活跃的片段进行清理，只有被关闭的旧片段才会被清理
        2、kafka会在包含脏数据的主题数量达到50%时进行清理，50%这个参数可以调整



可靠地数据传递：

    有些场景要求很高的可靠性，比如支付；而有些场景更看重速度和简便性，比如跟踪用户点击。kafka被设计成高度可配置的
，而它的客户端API可以满足不同程度的可靠性需求

    kafka可以保证的方面：
        1、kafka可以保证分区消息的顺序，如果使用同一个生产者往同一个分区写入消息，比如消息B在消息A之后写入，那么
    kafka可以保证消息B的偏移量比消息A大，而且消费者会先读取消息A再读取消息B
        2、只有当消息被写入分区的所有同步副本时，它才被认为是已提交的。生产者可以选择不同类型的确认，比如消息被
    所有副本同步时确认、或者消息被写入首领副本时确认、或者消息被发送到网络时确认。提交成功不一定是写入磁盘成功
        3、只要还有一个副本时活跃的，那么已提交的消息就不会丢失，前提是配置了：acks=all，否则可能有部分丢失
        4、消费者只能读取已提交的消息

    构建一个可靠的系统需要作出一些权衡，kafka可以在配置参数上作出权衡，从而得到想要达到的可靠性。这种权衡一般是
指在消息的可靠性和一致性，与可用性、高吞吐量、低延迟、硬件成本之间来权衡。因为它们之间往往做不到很好的兼顾，只能
根据系统的特点做出取舍

    broker有3个配置会影响到kafka消息存储的可靠性。这3个配置同样可以用在broker级别，也可以用在主题级别，如下：

        replication.factor(主题级别)：
        defaul.replication.factor(broker级别)：

            复制系数，默认为3，代表每个分区总共会被3个不同的broker复制3次。不过即使主题创建后，也可以通过新增或
        移除副本来改变复制系数

            如果复制系数为N，那么在N-1个broker失效的时候，仍然能够从主题读取或写入数据。所以更高的复制系数会带来
        更高的可用性、可靠性和更少的故障。另一方面，N个复制系数代表至少要有N个broker，会存在N份数据副本，会占用
        N倍的磁盘空间。我们一般会在可用性和存储硬件之间做出权衡

            如果复制系数为1，就代表主题不可用时可接收的。如果复制系数为2，看起来可以容忍一个broker发生失效，但是
        有时候旧版kafka的一个broker失效会导致需要重启集群控制器。也就是说，如果复制系数为2，也有可能因为重启等问
        题导致集群不可用。

            基于以上几点，一般建议在对可用性有要求的场景里把复制系数设置为3，大部分情况下这已经足够安全了，不过
        有些银行会使用5个副本，以防不测

            副本所在的服务器的分布也很重要。默认情况下，kafka会确保分区每个副本被放在不同的broker上。但是如果这
        写broker处于同一个机架上，一但机架的交换机发生故障，分区就会不可用，此时复制系数再多都没有。因此最好把
        broker分布在不同的机架上，并使用broker.rack来设置机架名称，kafka将会把副本分布在不同的机架上，以获得更高
        的可用性


        unclean.leader.election(只能配置在broker级别)：

            不完全的首领选举，默认是true。允许不同步的副本称为首领，true代表更高的可用性，false代表更高的一致性

            前面说过，当分区首领不可用时，一个同步副本会被选为新首领。如果在选举过程中没有丢失数据，也就是说提交
        的数据存在于所有的同步副本上，那这个选举就是完全的。但是如果当首领不可用时，其它副本都是不同步的呢？此时
        会有两个场景：
            1、首领奔溃后就没有其它副本了，此时如果有一个跟随者启动，它就成了分区唯一的不同步副本
            2、首领奔溃后，依然有其它副本，不过它们都是不同步的，由于它们是不同步的，首领奔溃后就再不可能同步了
            此时只有两个选择，要么不同步副本不能提升为首领，这将导致在首领重启前整个分区不可用。要么将不同步的副
        本提升为新首领，此时不同步的那部分数据将会丢失，导致数据不一致

            考虑一种场景，如果副本0是首领副本，它拥有0-200的消息，副本1是不同步副本，它拥有0-100的消息。此时副本
        0发生奔溃，如果副本1成为新首领，那么生产者就可以继续写入数据，它将拥有新的100-200的消息，那么部分消费者
        读到的就是100-200偏移量的新消息，还有可能部分消费者在100-200偏移量之间读到了副本0与副本1混合的消息。因为
        它们只认偏移量，而不管broker是谁。当副本0重启后，它会把比当前首领旧的消息全部删除

            因此，如果我们允许不同步的副本称为首领，就要承担丢失数据与数据不一致的风险。如果不允许它成为首领，就
        要接收较低的可用性，因为必须等待原来的首领恢复或者能刚好存在同步副本


        min.insync.replicas(主题与broker里都可用)：

            最少同步副本，代表分区最少存在几个同步副本才能向分区写入数据。

            如果要确保已提交的消息被写入不止一个副本，就要把这个参数设置大一点。如果副本数为3，那么这个参数被设置
        为2就代表最少有两个同步副本才能向分区写入数据。
            此时如果一个副本不同步，那不会有什么问题，如果有两个副本不同步，那broker就会停止接受生产者请求，生产者
        客户端发送消息将会收到NotEnoughReplicasException异常。不过依然可以对这个分区已有的数据进行消费。这代表该分
        区变成了只读
            这能避免发生不完全选举时，数据的写入和读取出现非预期的行为。如果要从只读状态恢复，就必须让两个不可用分
        区中的一个重新变为可用，并等待它变为同步的

            这个参数跟acks有点类似，不过acks只管同步副本的写入，即使只有一个同步的首领分区acks也会写入成功。而这个
        参数能限制最少存在个同步副本才能写入





























